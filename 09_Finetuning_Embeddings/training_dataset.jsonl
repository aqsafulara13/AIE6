{"questions": {"9566dbb0-0eb1-44bc-af90-d82c3e1ff7cb": "QUESTION #1", "97901eac-762a-41c8-8b26-e5bc1d1ff99d": "What significant development in the field of Artificial Intelligence is highlighted as having occurred in 2023?", "008eb4de-0553-4a03-9706-5607f9df709a": "QUESTION #2", "598dace2-a720-4d93-9361-309f70fc910e": "According to Simon Willison\u2019s weblog, how are Large Language Models (LLMs) characterized in relation to AI?", "6e623980-1a88-43d0-b118-87f16601ef41": "QUESTION #1", "bdd6e5c5-e5e1-4b43-a036-38e65c74d133": "What is one reason why building Large Language Models (LLMs) is considered relatively easy according to the context?", "13a5fd99-a595-4805-92dc-ed03aae7143f": "QUESTION #2", "5693817b-0ec0-47bf-85b8-b95317e13d52": "What is identified as the biggest unsolved problem related to LLMs in the provided information?", "a3fdc147-ec83-4cf3-844e-738c812bf3b3": "QUESTION #1", "b0f59d21-25ff-4928-8147-3c3cf966a73a": "What are some of the capabilities of Large Language Models (LLMs) as mentioned in the context?", "33f11349-147d-49d9-b353-18303403bc2e": "QUESTION #2", "f96ed5cf-e4d5-42ce-b514-0120124093b6": "What are some potential negative uses of LLMs highlighted in the provided information?", "6bba8fb6-f4ad-451d-8568-4eb69a5c42f2": "QUESTION #1: According to the context, what are some ways the author has personally used LLMs to improve their life?", "981aa468-f104-44e8-8f38-26a184421cf3": "QUESTION #2: What is the most surprising recent discovery about LLMs mentioned in the text?", "cb8e65ad-138f-4efc-b6f6-fac4c06bf3cc": "QUESTION #1", "1360d544-6dd6-471e-81c3-9e9542acf1a8": "What is considered the most important factor in determining the quality of a language model according to the context?", "ddec775a-2cd9-4df9-99d3-b445f019af75": "QUESTION #2", "365aa4f1-0178-45a4-abe6-cd32b4c7c2bd": "According to the passage, what is surprisingly sufficient to train a basic version of a powerful system?", "18dac1cd-61ea-45dc-b8dc-21d2645288c8": "QUESTION #1", "6cd3c537-2493-4210-afc3-98b3c2da4e3c": "Which organizations have recently produced models that are considered better than GPT-3?", "ae2cb6f6-c784-4869-b538-75032da5d9df": "QUESTION #2", "01d465ea-3e29-4b21-9a81-e4fedfd2476b": "How has the estimated training cost for large language models changed over time, and what is the approximate current cost for Microsoft\u2019s Phi-2 training run?", "60ff5093-63ba-4afb-aa1a-6e9cba579a4a": "QUESTION #1", "e82d13db-d778-4015-bab7-7a1c71e470df": "How does the author compare the difficulty of training a large language model (LLM) to building a suspension bridge?", "82deb276-99bd-41f8-b1ad-a54cddce0c67": "QUESTION #2", "54e8cf1f-4a48-4ed5-bb34-3844c1d5d546": "What change in the availability or accessibility of running LLMs on personal devices does the author mention?", "94196339-1259-4f23-9499-e7cac5296891": "QUESTION #1", "24fc7ea1-a200-4877-8152-a59bd8bfd2f2": "What significant event regarding Meta's language model occurred in February, and what development followed in March?", "174eea55-9655-4648-8a54-43ea96981ae0": "QUESTION #2", "1c3c9cf9-d16a-4331-bf7a-b664a3b96e7f": "How did the release of Llama 2 in July impact the landscape of large language models?", "b4180c01-98dd-469f-bbed-6866f8c4394e": "QUESTION #1", "d7ea2e2e-13f5-42a1-881f-9a90c07ece3d": "What method does the context mention for running an LLM entirely in your browser?", "445a242f-e816-4fbf-8afa-bb71c927f032": "QUESTION #2", "6349548e-6d72-49cb-9013-4d9ca1b68a68": "According to the context, what is the difference between training a new LLM from scratch and fine-tuning an existing model?", "dd0626ab-2128-418a-9fd0-434f69f547e8": "QUESTION #1", "13b8983e-7aa1-481e-acee-a985e74236a9": "What is the primary advantage of open models over closed models according to the provided context?", "b735f4ae-68c7-4c15-a7ec-dd09674ff043": "QUESTION #2", "ec4ae2a9-fb83-480c-a0f4-dd04b76b89f8": "Why is it difficult to accurately count the number of models on the Hugging Face Open LLM Leaderboard?", "9455cd0f-5033-48ed-aeb9-ddd0ed89f2eb": "QUESTION #1", "da8084e8-caec-4091-bfa4-409cf03e360d": "What is the current status of alternative models to GPT-4 according to the provided context?", "9cb51f32-7712-4129-93be-87fcf363d3ce": "QUESTION #2", "d86bae3c-b1c9-41cc-9b1a-3c864ba825b5": "Which company\u2019s upcoming model, Gemini Ultra, is mentioned as having big claims but is not yet available for testing?", "c9be5272-f319-4a87-8fec-d3d0b890e609": "QUESTION #1", "58e0e619-72c8-46a8-9ea6-d9121a1e6f18": "What does the author imply about OpenAI's GPT-4 in comparison to other language models?", "c4944994-f37b-403e-8749-6709d6fc22ae": "QUESTION #2", "4dac1631-5d16-4fbf-831a-393b08ad6797": "According to the context, what are some of the challenges faced by computer scientists and software engineers when working with large language models (LLMs)?", "25069657-5fec-448e-b7fb-4afebcdf2d62": "QUESTION #1", "73983ec8-2861-4ef2-a9ad-7ba707a13999": "What challenges does the author mention regarding evaluating the effectiveness of prompts when working with an LLM?", "5cbace73-3ec9-4dc2-be2a-6908ea1ae481": "QUESTION #2", "cc69fbc7-e24c-48dd-a148-0da7c3a0eb08": "Why does the author describe their current approach to prompt tuning as \"Vibes Based Development,\" and what do they hope will improve in 2024?", "1d806264-08d9-4ef6-8d96-e879f3408d38": "QUESTION #1", "d2e967db-281c-423d-b967-12e77d7c4ad1": "What are some of the unexpected capabilities of LLMs that the context mentions?", "4185575d-814b-4a9a-9944-72a1e21d242e": "QUESTION #2", "229f71e0-675b-49ab-81fb-d7c9bd7701e3": "Why might ChatGPT's responses change in December, according to the context?", "b54a48d6-650b-4b70-bd1b-de661f691143": "QUESTION #1: What strategy does the author suggest to improve the quality of responses from the AI, and what is the rationale behind it?", "3f7608eb-738b-4474-8c67-c0c134f5fc1b": "QUESTION #2: How does the author relate the concept of gullibility to the broader challenges faced in AI security and reliability?", "a231b07d-0bb7-40e6-93a9-c83d33b05c8b": "QUESTION #1", "b80023c9-e0ab-47d8-9348-96d27b72b659": "Why is it important for language models to sometimes be less gullible or less likely to believe everything they are told?", "89cf87ad-7b0c-4e4c-8daa-4d7b0bbc9730": "QUESTION #2", "c99b7625-150e-4659-865c-65236e544e67": "What is a potential problem with a real-world personal assistant who believes everything they are told, according to the context?", "c2ebb62c-652a-4225-803e-eb7c12a1604e": "QUESTION #1: Why does the author believe that the widespread excitement about AI agents may be premature or misplaced?", "d30313cf-d634-4907-85dc-3950697280ba": "QUESTION #2: According to the context, what is considered one of the most effective applications of large language models (LLMs)?", "263f5e6f-295c-4a90-abfc-edac9ed99c93": "QUESTION #1", "8a657ca9-1f3e-4644-89ef-9fd6c5a765a9": "Why might the grammar rules of programming languages like Python and JavaScript be considered less complicated than those of natural languages such as Chinese, Spanish, or English?", "35888ba5-13c6-409a-9cd9-1bf296b39f6c": "QUESTION #2", "b94aa6bc-7523-44ea-9562-bccc5f543847": "What is one of the major weaknesses of large language models (LLMs) mentioned in the context, and how could this weakness impact their usefulness in coding?", "a45533d0-5ff8-476e-9408-291f2d681258": "QUESTION #1", "8d81a741-7548-4f95-bcae-eeb1527d9e9f": "What advantage does the ability to run generated code provide when using tools like ChatGPT Code Interpreter?", "840fa455-4398-4d64-9f5a-18c9d2cfeadf": "QUESTION #2", "cbf729d2-eb59-4584-87f9-c7d1f58c7537": "Why does the author suggest that hallucination is a lesser problem in code generation compared to other areas, and what is the implied challenge for fact-checking natural language?", "d5866311-3146-47bb-9c90-91040fcc9437": "QUESTION #1", "64701e65-5c61-466c-beae-dc5591e8a9ac": "How can software engineers leverage their deep coding knowledge to better utilize interns in solving coding problems?", "87013628-c827-420f-9960-e70a73f0104c": "QUESTION #2", "5dd811e5-bad3-4005-bb31-a8c5903e182a": "What ethical challenges are associated with the use of unlicensed training data in large language models and image generation models?", "50765201-41ce-4883-9d1b-893b66893582": "QUESTION #1", "c379be47-7a50-4b84-85cf-b2740570980d": "What are some reasons the 69-page PDF from the New York Times lawsuit against OpenAI and Microsoft is considered valuable and easy to understand?", "b59d1620-8263-4aa8-86cb-149e50aa4546": "QUESTION #2", "b800a018-3d8c-46eb-869d-2f41acd73b94": "Why does the author believe that the legal case brought by the New York Times against OpenAI and Microsoft will have a significant impact on the future development of large language models (LLMs)?", "c55cb37a-58d7-45b8-92f3-74f1f2c5fd9b": "QUESTION #1", "294b5c76-b87a-4a50-aafa-24f7fc1c77ea": "What ethical considerations arise from training AI models on people's content without their permission, especially when these models compete with the original creators?", "0c1b143c-4831-4617-a1e5-959e2f0dc0a5": "QUESTION #2", "5cda5afb-a89a-4109-837e-64465f8945a2": "How has the increasing quality of AI models impacted human employment, and what kinds of jobs have been most affected according to the context?", "c15fe6ba-4fbf-4ee3-9ee3-bdd3c9bcfe78": "QUESTION #1", "ccb9a89b-36a1-4b23-8f1e-3521a4727d70": "What tools did the author use to extract and organize their annual website traffic data, and how did they incorporate entry titles into the table?", "3884a5b9-eec7-4945-8153-d9285841bb64": "QUESTION #2", "1a3e384c-6ee3-4bba-ad5f-b2c767f35787": "Which article received the highest number of visitors and pageviews according to the top entries listed, and what was its main topic?", "ff2f4ae6-d936-46c1-9f9b-f098f9e57b5d": "QUESTION #1", "336757a9-8910-46be-b023-8bf3d73dd443": "What are embeddings, and why are they important in the context of large language models (LLMs)?", "c6dec6a8-d832-4b95-86e9-491821434a10": "QUESTION #2", "84df49e7-848f-4df3-aeec-3cd57c4b8489": "How can GPT tokenizers impact the way models process and generate text?", "5138d00d-a477-41ec-87d7-9f49d3949360": "QUESTION #1", "878036e5-0a98-45e6-bc9a-41dd31cf0fed": "What is the significance of running the vicuna-7b Large Language Model entirely in your browser as mentioned in the context?", "73c13380-0917-4b49-b762-7afeda48f36b": "QUESTION #2", "88b67fd8-5bb0-4c84-a93c-36c4c516be0e": "How does the context describe the limitation of ChatGPT regarding internet access?", "e467f192-15b8-43f9-b8a7-e710e55454d1": "QUESTION #1", "418318a5-a227-4bc5-ac20-68432d0c8549": "What topics did the author cover in their annotated presentations from 2023, and can you name at least three of them?", "2bb34a22-78ed-4947-9ab6-e346da822b12": "QUESTION #2", "cef00f8b-378c-4056-818e-39c6a0844cc8": "Which podcasts did the author appear on, and what were some of the subjects discussed during these appearances?", "23d4bb76-8cc2-46c2-bb3e-2919ac86498f": "What is the main topic discussed in Simon Willison's article posted on December 31, 2023?", "ba00aa50-f001-4711-8c46-a9e4eb115c9c": "Which specific AI vulnerability is mentioned as having a delayed industry response in the context?", "426b77bd-5da5-4a6d-8c42-23a0355e8d8a": "What are the three main topics listed with their respective numerical values in the provided context?", "c7cbca2b-8284-494f-80a3-cc80310ef8e2": "Which individual is mentioned in relation to the \"formidable power of escalating streaks\"?", "be62725c-7116-4f16-b588-d44dd7c99004": "QUESTION #1", "4eb29041-ec8f-4e04-814a-ab0fc28df84f": "What are some of the key themes and pivotal moments identified in the developments of Large Language Models in 2024 according to Simon Willison?", "d56a8031-bc7a-4172-b4ad-e8e92977c851": "QUESTION #2", "3651e377-3961-4287-8c67-e3fa6475a5e0": "How does the 2024 review of Large Language Models compare to the previous year's insights, as discussed in Simon Willison\u2019s weblog?", "fc3ded65-9500-48ce-af03-a4682acdb521": "QUESTION #1", "86e048a4-ee0d-4aa2-86ab-4920d91e0dab": "What advancements indicate that multimodal vision, audio, and video capabilities are becoming more common in AI models?", "3cd46f5b-a1c9-4d08-b414-54da3a1a482e": "QUESTION #2", "68c10021-6d1d-43c9-8abc-27ab0c93c555": "According to the context, what is the current status of \"agents\" in AI development, and why might they be significant?", "9708b6b4-c540-470a-bce6-79a780de48df": "QUESTION #1", "2e199d16-321c-4092-8f4b-c9e5cbda50ff": "What challenges are mentioned regarding the usability of large language models (LLMs) in the given context?", "40d631e8-bc35-4e7e-83f1-a7c24fe8225b": "QUESTION #2", "52403542-3ecc-483a-ab63-4ddb71c8edcc": "According to the context, what is suggested as a necessary improvement for LLMs moving forward?", "0cde4351-66b8-4c27-89b5-1d4dfb605257": "QUESTION #1", "b8270166-e996-428f-af0c-3b65199f899a": "What was the status of GPT-4's development and performance as of December 2023, according to the review?", "c97c6990-659d-461e-86e5-48c17c068c68": "QUESTION #2", "cebd050c-83b1-40b6-a5f1-9bd874f9fa18": "How many organizations now have models that outperform the original GPT-4 on the Chatbot Arena Leaderboard, and what is the total number of models that rank higher?", "dc529af4-2a10-4c8d-8ae1-76eb428aabc1": "QUESTION #1", "8e4a280f-3dc4-41d7-adf2-111095ead9a1": "What are two notable new capabilities introduced by Google\u2019s Gemini 1.5 Pro?", "b0a4565e-d65f-49a7-a71d-54c7a146ba27": "QUESTION #2", "e2d2776f-def6-49bc-bea4-74b099c121a1": "In what event did the author make a brief appearance as a talking head related to Gemini Pro 1.5?", "e92cc911-6ca2-4a66-8351-6a995a0d7855": "QUESTION #1", "1d198f50-2834-4086-acd7-81406ab32890": "What is one of the key themes of 2024 highlighted by Gemini 1.5 Pro?", "f35938c1-510a-4ad8-a0a7-79423f1bca0d": "QUESTION #2", "f132833b-8c46-45b6-a0db-59712743c219": "How does Google\u2019s Gemini series compare to other models in terms of maximum accepted tokens?", "89df69e3-302b-4a99-896d-038b6318baaf": "QUESTION #1", "7d2750ef-78b5-4f22-a763-7a2e1c30303d": "How does increasing the length of inputs enhance the capabilities of an LLM in solving problems?", "f879ccbb-55e4-4967-9ccb-6541caffcd44": "QUESTION #2", "b67d3df0-cb55-40c6-8716-15e5973932b5": "Why does the author find long-input use cases more interesting than short prompts that rely solely on the model's pre-existing knowledge?", "4329f2fc-325a-4d16-98d7-5dc535a32502": "QUESTION #1", "afd1e6e7-1adf-47a1-9a7d-8435fceea515": "What model did the author consider their favorite daily-driver after its launch in June?", "55d83188-0a12-4255-a75b-2b761e0b7ea9": "QUESTION #2", "23620a20-d46a-461a-8ff5-f8ff2dc54978": "Why do fans refer to the upgraded version of Claude 3.5 as Claude 3.6 despite it having the same version number?", "3d83f357-a428-4c9a-89cb-e0d88db2fc77": "QUESTION #1", "3f4c58e2-3bc1-4be8-a415-0755ae2707d2": "Which organization\u2019s model currently ranks around 70th place on the Chatbot Arena leaderboard?", "4ef79349-1e07-419b-9fbd-525d56c84973": "QUESTION #2", "b4f72b3d-984e-49d3-8261-1fbe5fd3e714": "Why does the author suggest that training a GPT-4 beating model was a significant achievement in 2023 but less notable in 2024?", "a2592a8a-95e7-4be7-84b6-fd36d1f57a32": "QUESTION #1: How has the user's MacBook Pro's capability changed from March 2023 to the present regarding running large language models?", "2e6c2721-9d83-421a-82fa-16bf4346e97d": "QUESTION #2: What significance does the user's experience with their MacBook Pro have in relation to the evolution of large language models like GPT-3 and GPT-4?", "21026bc7-0f4c-417b-bd00-eaeb4c7d47f1": "QUESTION #1", "641c0088-5fde-4243-88c2-2cfff9b2e4d8": "What is the licensing type of the Qwen2.5-Coder-32B model?", "65c6bbcd-476b-4592-84fe-f003589e1cc9": "QUESTION #2", "30ce6bad-9500-4dda-9a9c-5f30e4022761": "Which large language model is mentioned as being capable of running on a Mac and is comparable to GPT-4?", "fdad1781-d98d-408a-b2d0-762cab9f3b1f": "QUESTION #1: Why does the author find it astonishing that models like GPT-4 can run on their hardware setup?", "fc1578ea-ef2f-4ec3-b088-b74c9a7e3372": "QUESTION #2: What has contributed to the ability of models like GPT-4 to run despite their high resource requirements, according to the author?", "c832e829-56c7-4483-81af-bdfe328c5e9b": "What are the sizes of Meta\u2019s Llama 3.2 models mentioned, and how do they compare to GPT-4?", "c096ee40-6015-4587-a5e8-3c30410cdc83": "How does the user describe the performance and capabilities of the Llama 3.2 3B model when run on an iPhone?", "f67ea233-1373-448c-b3e1-a2f4dd01217f": "QUESTION #1", "8412ef09-0bb0-4ab0-9743-e0be5d2040e5": "What recent changes have occurred in the pricing of large language models (LLMs) like GPT-4 and GPT-3.5 Turbo?", "141981c1-eb69-4b39-aad6-75f2b8c43537": "QUESTION #2", "bb70c549-cc87-4ece-9056-8d1d6d233c0b": "How has increased competition and efficiency impacted the cost of running prompts through top-tier hosted LLMs over the past year?", "a9fb34d4-3049-4b8a-986b-12e8d2391c30": "QUESTION #1", "bc72beb0-c926-428d-9998-f2c28bf28ecc": "How does the cost of GPT-4o mini compare to GPT-4 and GPT-3.5, and what does this imply about its capabilities?", "b7c175a3-86d8-47cc-a4bf-377eef5c5261": "QUESTION #2", "129c2aab-9911-4955-a528-cd260166ced4": "Which model provider offers the cheapest option among those listed, and what is its price per million tokens?", "c66bca39-6958-477b-a7bd-f5408c173c26": "QUESTION #1: What are the two main factors driving the recent price drops in large language models (LLMs) as mentioned in the context?", "dda837ca-a996-4c43-b448-488f97d5e602": "QUESTION #2: How has increased efficiency impacted concerns about the environmental cost of running individual prompts with LLMs?", "28fff0fe-cec6-4dcd-b86f-d40cde7075fb": "QUESTION #1", "7ad1c918-3ae5-4e4c-ae69-c677f97fb797": "How is the total cost of processing 68,000 images calculated, and what are the individual costs for input and output tokens?", "7308d0a3-08c7-4ed8-a1c6-ef68fd55405a": "QUESTION #2", "018d0329-3c42-4a9f-ac7b-2aecf199e7e4": "What command was used to generate descriptions for the images, and what does it reveal about the quality of those descriptions?", "a50e7d23-6aa0-4fc0-af98-9e0a6b184339": "QUESTION #1", "62313af3-e445-41a1-82cc-371b6f8a5376": "What types of butterflies are shown in the feeder at the California Academy of Sciences, and what are their distinguishing features?", "15130afc-8fc4-4e0d-bf93-c5b844d9726f": "QUESTION #2", "4fe36d59-e848-43ae-a01e-03730e59ef9e": "What is the likely purpose of the red shallow dish with orange slices in the photograph?", "eba91ce5-88ba-401f-87d0-9227d3b71179": "QUESTION #1", "b2b8ece6-8c2b-4353-b0f6-35de5a09fa8c": "What is the significance of the increase in efficiency and reduction in price of language models mentioned in the context of 2024?", "71c2e842-0b32-44cd-8a91-2fb0366d5892": "QUESTION #2", "fa6a7393-9970-4980-af8d-068b3370a14c": "Which two multi-modal large language models are highlighted as notable examples from late 2023 and early 2024?", "84634ce9-f22e-48f7-b4dd-743b89bace80": "QUESTION #1", "9f098ff2-8ec3-49f0-a070-12da0c1dd3c5": "Which companies released multi-modal models in 2024, and what types of modalities did they include?", "41fcfd5c-3bb0-4abf-8871-c7e60541e49b": "QUESTION #2", "2bccdf2f-466c-4a07-8b5d-94c3ff9ac40c": "What recent upgrade was made to the LLM CLI tool in October, and what functionality does it now support?", "107d0054-6589-4c39-8f6b-a0b6ede62629": "QUESTION #1", "a67215c5-4a67-4c81-b2c2-f3a9dc2fcedc": "What are some of the significant recent advances in multi-modal models that the context highlights as often overlooked by critics who say LLM improvement has slowed?", "dec724bd-34c8-4710-9fab-034de7174f0f": "QUESTION #2", "c4f1e408-bb68-41ab-b70e-d12a6c211000": "How did OpenAI enable conversations with ChatGPT in September 2023, and what limitations did this implementation have according to the context?", "b529f089-e589-46f2-9564-7be083229870": "QUESTION #1", "1fe35594-9ada-4e9f-b518-f7ab0ef49596": "What feature was demonstrated in the May 13th announcement of GPT-4o that showcased its multi-modal capabilities?", "b1367d10-da3b-4341-9c79-1f494c47e08f": "QUESTION #2", "769b2544-9c9f-4c54-97a0-56b0c69274ce": "Why did the voice from the demo, which sounded similar to Scarlett Johansson, never make it to a production product?", "5d150d61-872b-4d0c-ab98-f97f81d10cff": "QUESTION #1", "28a5723e-7531-4712-bd59-09d7b2523c4b": "What features of ChatGPT Advanced Voice mode did the user find particularly impressive during its rollout?", "3a744455-161f-4493-9039-cdade96697c9": "QUESTION #2", "758ff43c-4a3f-4165-8c4c-aac3da1803bf": "How did the user experiment with the OpenAI audio APIs, and what specific accent and language did they request ChatGPT to use?", "3baa5994-456a-473c-9cad-6771b7ecfa2f": "QUESTION #1", "dedbefbc-5622-4889-813e-d9dc45eaebea": "What feature did Google\u2019s NotebookLM introduce that enhanced audio output capabilities?", "0dc10ac9-f689-4101-9369-f70ecb294238": "QUESTION #2", "4738a635-d3fb-49fa-9c2e-5794ff314ca8": "When is Amazon planning to roll out the voice mode for Amazon Nova?", "7da7e5a7-0260-45ff-b401-0a61ee1c57f7": "QUESTION #1", "8b3a431f-f875-43df-9e68-fe944304d5f1": "What new feature related to live video and camera sharing has ChatGPT introduced in its voice mode?", "8ee1ad98-4f55-40d8-a099-e721bf76426c": "QUESTION #2", "eb66e765-1f9b-4237-a6dd-6f95843fec55": "Which company announced a preview of a similar live video sharing feature just one day before ChatGPT?", "f4ff9b0d-9d41-417a-88c2-937ea0b8bf76": "QUESTION #1", "1c28405a-5c72-47dd-87dc-e1cfe12f81ba": "What recent changes did OpenAI make to their WebSocket API, and how has it impacted the ease of building voice-enabled web applications?", "f2195d18-bc21-47e8-a471-04200290571b": "QUESTION #2", "9443c53c-4650-487f-932b-e25d135268e6": "According to the context, how has the value of prompt-driven app generation evolved from 2023 to 2024?", "37d384ee-da11-41af-a69e-6eab911ab378": "QUESTION #1", "4fb8771f-ad91-4d00-bff3-a7ede207ab34": "What capabilities do large language models (LLMs) have when prompted correctly, according to the context?", "5adfb3ff-b59f-4901-9261-f78522ca216e": "QUESTION #2", "df20511b-1c06-43e6-84ab-e5ee7d8d0a93": "What is the significance of Anthropic's Claude Artifacts feature as described in the context?", "c5cdd213-ac1d-4fb7-965b-ce6a3d5d0fff": "QUESTION #1", "ca066e8d-fe94-47ba-afba-59e1869dd181": "What did the author do in October related to the tool they have been relying on?", "cb5e7558-6de9-451b-a9fe-7a7ba2744e17": "QUESTION #2", "9d89ca83-8b07-4f46-9a03-fb250add5ba1": "Which companies or teams have built or announced similar systems to the one described, and what are their names?", "f647186a-8e31-4847-8711-3bc72d709bc5": "QUESTION #1", "ce4ab675-887e-4f34-a2d4-59b635194483": "What new feature did the Chatbot Arena team introduce in December, and how is it driven by user interactions?", "7e52f4b0-507f-4496-bf0a-ab78bf2565e4": "QUESTION #2", "ae1205b5-3c75-4152-8524-98d7e6049d35": "How has the author been experimenting with the feature in relation to their Datasette project, and what capabilities have they been exploring?", "0ded3534-521f-4cb3-8ed5-2b0a82dd6d29": "QUESTION #1", "f7055319-5aba-45fe-b98e-b492323294e4": "What is the anticipated timeline for the widespread adoption of the prompt-driven custom interface feature in various products?", "dc6f9018-25cd-40dc-a593-182ff992641d": "QUESTION #2", "810a07f8-e66e-417f-876b-ed8f248f5a90": "Which three models were freely available to most of the world for a few short months this year?", "82df5139-78c3-4ed5-8e37-aa90f66934c0": "QUESTION #1", "fc67e339-1216-4ab5-ac34-16ff6e665105": "What significant change did OpenAI make in May regarding GPT-4o and how did it impact user access to advanced models?", "aa8f0ebd-2c6f-4860-a07f-da00055bdbcd": "QUESTION #2", "942c8636-6a6b-408b-8794-c2994bada9af": "Why does the author believe that free access to the most capable models, like o1 Pro, is unlikely to return in the future?", "261e58fd-1c8b-493d-b2d2-4fba898410ad": "QUESTION #1", "b7c1e280-0c57-434a-afd8-30f6473ec963": "Why does the author find the term \u201cagents\u201d frustrating?", "dff66871-4063-476e-bb54-190986756137": "QUESTION #2", "960f3f37-54d6-497c-8c7c-335f3b40499c": "What is the main issue the author has with the way the term \u201cagents\u201d is used?", "cc611f91-7e7f-4c95-9954-6ff6273e23f0": "QUESTION #1", "3fa35071-9398-470d-9986-b9a01f232f8a": "What are the two main categories of AI agents described in the context, and how do they differ in their approach to acting on behalf of users?", "f9a6a704-a37f-458c-9cb7-07a4ae56e307": "QUESTION #2", "0181ef15-2ce1-45eb-947b-aa9eca492f87": "Why does the author suggest that the term \u201cautonomy\u201d is often used without a clear definition in discussions about AI agents?", "c2b7ea50-c446-4749-acaf-6587ec5af94b": "QUESTION #1", "23b520a4-d7ad-42f9-b417-33c6c3b48de4": "What is the main concern raised about the utility of systems like LLMs, digital assistants, and research tools in the given context?", "93aeb3d7-c716-4613-a0b4-82840308e301": "QUESTION #2", "8248663f-7443-400a-a4eb-201b0227c547": "How did Google Search demonstrate the challenge of gullibility mentioned in the passage?", "5f557a45-ad35-480c-86da-6dc2a7a4ea0b": "QUESTION #1", "bb249340-4c46-44d2-a37b-8194c642b33b": "What has been the main challenge in addressing prompt injection since it has been discussed since September 2022?", "b65c1e76-ebf8-4f2b-b989-46968cb58b37": "QUESTION #2", "0dbdf213-0ee3-40cc-ab18-30c2be136351": "Why does the author consider developing a model robust against gullibility to be a \"very tall order\"?", "4cd1dd4a-6614-45b3-b67b-133b27dd4b09": "QUESTION #1", "86626d8e-212f-4ada-aa14-99be48a832f0": "What is the key approach to creating effective system prompts according to the provided context?", "4479043a-ba20-455c-ba8b-20b21d76032c": "QUESTION #2", "e12e46e6-b94b-4ab5-b306-868830589575": "Why is having a strong evaluation suite important for developing LLM-powered applications in 2024?", "f7c18978-06ec-4f03-9cbb-7c419eb5004f": "QUESTION #1", "44b8b7c0-614d-43d7-af50-f6fa1baf14de": "What was the initial approach to protecting the prompt when @v0 first came out, and how did it change over time?", "2d118a5a-a5cc-4a1f-99f6-239e0d33f7d4": "QUESTION #2", "6153f124-2754-4aff-afb1-e75b84a539b4": "Why does the author compare a prompt without evals, models, and UX to a broken ASML machine without a manual?", "76be9d18-9309-4719-be0b-934a906d9841": "QUESTION #1: What challenge does the author mention regarding implementing evaluation (evals) for their work?", "dcd16b1c-03e1-4ee8-a590-f553b58d454a": "QUESTION #2: How does the author compare Apple\u2019s MLX library to Apple Intelligence?", "d96d3b44-863d-4785-ac36-35381f75efa2": "QUESTION #1", "8307cc9e-e5bb-4fc0-9b00-9347db56c399": "What is the significance of a 64GB Mac in running models, and how does its architecture benefit this process?", "ee9257bb-4e2e-4543-8611-7130a9636d70": "QUESTION #2", "29875337-5236-4de5-9675-2125735889ac": "How has Apple's MLX library and mlx-lm Python library contributed to running machine learning models on Apple Silicon Macs?", "b0123edd-2fdd-4226-be6f-ea2d4b53b7be": "QUESTION #1", "0c50d46d-3d90-40f2-a2dc-bb2c813747ad": "What recent project by Prince Canuma brings vision LLMs to Apple Silicon, and what specific model was run using it?", "97ea6cef-a458-43b2-a780-ff378a19fa64": "QUESTION #2", "44d9846d-c4cc-440c-bc0b-b3b6b5f75f9e": "How does the author compare the impact of MLX to Apple's \"Apple Intelligence\" features, and what was their initial expectation regarding Apple's focus on privacy in these features?", "091c9326-1b12-42f0-af6d-ed868fc51dfa": "QUESTION #1", "ab21d9cb-72ed-4d96-9a1e-a654ece91083": "What are some of the limitations of Apple's recent LLM features according to the user?", "e85559ad-7074-4646-9702-77b3150f13d8": "QUESTION #2", "e0500759-8ad1-4935-8c6b-553cb13ffe84": "Which new type of LLM model was introduced in the final quarter of 2024, and what are its examples?", "42bd5103-864a-4f19-b194-70e62441c618": "QUESTION #1", "02dc437e-2e92-4a89-8292-94b8e80d71f4": "What is the main idea behind the chain-of-thought prompting trick as explored in the May 2022 paper \"Large Language Models are Zero-Shot Reasoners\"?", "6f8a60e2-ed27-4c22-ae1c-95f98a178632": "QUESTION #2", "3038ff4c-44f4-4cb6-9055-4bf022a1fa87": "How does the o1 model differ from the traditional chain-of-thought prompting approach in terms of processing reasoning tokens?", "a6ecb07a-9a5c-4163-a7fd-91c529854dd9": "QUESTION #1", "4f9b48f9-19f0-4f1e-9bd4-0a555fa50c71": "What is the main innovation described in the context that allows models to handle harder problems without solely relying on increased training compute?", "b093df04-3637-4035-bb2a-787269daeef2": "QUESTION #2", "7f44c093-2ce5-4fc5-a116-73608ef11d65": "When was the sequel to o1, o3 announced, and what notable achievement did it demonstrate?", "64113107-e2b9-4309-b2cf-0bff76f67537": "QUESTION #1", "f1848890-85ce-4fdc-98eb-183bb7a2923a": "When did Google release their first entrant in the category, gemini-2.0-flash-thinking-exp?", "122fb62c-ab2b-4646-af2b-a830aead3697": "QUESTION #2", "e8031301-5238-4a7b-bb65-1ffb930ad52e": "Which company released the QwQ model under an Apache 2.0 license, and when was it released?", "28c890ad-a28a-48e5-a89b-4af4c7950545": "QUESTION #1", "1a287c09-e164-4c43-930e-08f8b4cb8e37": "What is the significance of Meta's December publication titled \"Training Large Language Models to Reason in a Continuous Latent Space\"?", "fecfe119-aa9d-47a1-8a2a-15c5adc2bb45": "QUESTION #2", "131e2486-fc9f-400e-a2e3-887146a48af6": "What was notable about the release of DeepSeek v3 on Hugging Face, and how did the accompanying documentation and paper follow its initial release?", "bb84b0d2-8968-42f8-879d-f30fd7dd943f": "QUESTION #1", "06a4860c-4f39-4cf6-84a0-bafa9d12ebe4": "How does DeepSeek v3 compare in size and ranking to Meta\u2019s Llama 3.1 405B and other models like Claude 3.5 Sonnet and Gemini 2.0?", "d31bb84a-6b27-4d38-a3ad-0d45ddfe12b0": "QUESTION #2", "a6c6a875-ddd2-4bd7-b4a5-32dc20038aab": "What is notable about the training cost and GPU hours required for DeepSeek v3 compared to Llama 3.1 405B?", "d8dd4bf4-bbb7-49b9-aeba-4699b08ecb48": "QUESTION #1", "76b4b149-73c5-454c-9e67-df31fc33d963": "How have US export regulations on GPUs to China influenced training optimizations and environmental impact?", "1c5071e6-7a92-46f8-a305-06839bf1a6f6": "QUESTION #2", "950f1c4d-fcf2-45f9-9e33-e147f43f730c": "What is the reported change in the cost of running a prompt compared to GPT-3 days, and how do Google Gemini and Amazon Nova compare in terms of profitability?", "f48826e5-05c7-47cd-9db8-9a8e8ec9fc3b": "QUESTION #1: How does the author compare the energy consumption of individual prompts to other activities like driving or watching videos?", "aba8283d-8aef-4988-874d-726f80c91979": "QUESTION #2: What does the author suggest about the trend of training costs for models like DeepSeek v3?", "2d7ec6ec-9463-40b2-9fc6-8b39651b0852": "QUESTION #1", "b8b67056-b0d1-444c-aed3-9acdecd788c6": "What are the environmental concerns associated with the current and future infrastructure buildout by major tech companies like Google, Meta, Microsoft, and Amazon?", "428942cd-286f-4fe0-84f6-6cc806d66a15": "QUESTION #2", "c61b5e78-d685-4a99-9912-b2759d64a5cb": "How might the decreasing costs of training large language models and the high expenses of infrastructure influence the necessity of building new data centers and nuclear power stations?", "e9c21a42-5c78-430f-870a-a4ee43e31796": "QUESTION #1: What were some of the negative consequences of the rapid railway expansion in the 1800s, as mentioned in the context?", "af34ef70-06be-4c65-8855-b23e4c3b4e88": "QUESTION #2: How did the construction of multiple railway lines serving the same routes contribute to economic issues during that period?"}, "relevant_contexts": {"9566dbb0-0eb1-44bc-af90-d82c3e1ff7cb": ["2a265a8c-5ff0-44e0-9b1a-a125367ebdc6"], "97901eac-762a-41c8-8b26-e5bc1d1ff99d": ["2a265a8c-5ff0-44e0-9b1a-a125367ebdc6"], "008eb4de-0553-4a03-9706-5607f9df709a": ["2a265a8c-5ff0-44e0-9b1a-a125367ebdc6"], "598dace2-a720-4d93-9361-309f70fc910e": ["2a265a8c-5ff0-44e0-9b1a-a125367ebdc6"], "6e623980-1a88-43d0-b118-87f16601ef41": ["a79767c8-f778-4cb5-b3d3-685a1d16b398"], "bdd6e5c5-e5e1-4b43-a036-38e65c74d133": ["a79767c8-f778-4cb5-b3d3-685a1d16b398"], "13a5fd99-a595-4805-92dc-ed03aae7143f": ["a79767c8-f778-4cb5-b3d3-685a1d16b398"], "5693817b-0ec0-47bf-85b8-b95317e13d52": ["a79767c8-f778-4cb5-b3d3-685a1d16b398"], "a3fdc147-ec83-4cf3-844e-738c812bf3b3": ["bd552d84-ad46-4694-9d55-dc7e1d72fc87"], "b0f59d21-25ff-4928-8147-3c3cf966a73a": ["bd552d84-ad46-4694-9d55-dc7e1d72fc87"], "33f11349-147d-49d9-b353-18303403bc2e": ["bd552d84-ad46-4694-9d55-dc7e1d72fc87"], "f96ed5cf-e4d5-42ce-b514-0120124093b6": ["bd552d84-ad46-4694-9d55-dc7e1d72fc87"], "6bba8fb6-f4ad-451d-8568-4eb69a5c42f2": ["4ae49088-dbc8-4cbd-9ea6-3ec8309ab431"], "981aa468-f104-44e8-8f38-26a184421cf3": ["4ae49088-dbc8-4cbd-9ea6-3ec8309ab431"], "cb8e65ad-138f-4efc-b6f6-fac4c06bf3cc": ["9bd61495-3eb9-46e8-b21b-1e15e2f9a7c2"], "1360d544-6dd6-471e-81c3-9e9542acf1a8": ["9bd61495-3eb9-46e8-b21b-1e15e2f9a7c2"], "ddec775a-2cd9-4df9-99d3-b445f019af75": ["9bd61495-3eb9-46e8-b21b-1e15e2f9a7c2"], "365aa4f1-0178-45a4-abe6-cd32b4c7c2bd": ["9bd61495-3eb9-46e8-b21b-1e15e2f9a7c2"], "18dac1cd-61ea-45dc-b8dc-21d2645288c8": ["5386e9bd-322e-48d3-8231-c5d66a10f1e4"], "6cd3c537-2493-4210-afc3-98b3c2da4e3c": ["5386e9bd-322e-48d3-8231-c5d66a10f1e4"], "ae2cb6f6-c784-4869-b538-75032da5d9df": ["5386e9bd-322e-48d3-8231-c5d66a10f1e4"], "01d465ea-3e29-4b21-9a81-e4fedfd2476b": ["5386e9bd-322e-48d3-8231-c5d66a10f1e4"], "60ff5093-63ba-4afb-aa1a-6e9cba579a4a": ["1c28d635-7bec-4e78-b1c7-eddaab684e64"], "e82d13db-d778-4015-bab7-7a1c71e470df": ["1c28d635-7bec-4e78-b1c7-eddaab684e64"], "82deb276-99bd-41f8-b1ad-a54cddce0c67": ["1c28d635-7bec-4e78-b1c7-eddaab684e64"], "54e8cf1f-4a48-4ed5-bb34-3844c1d5d546": ["1c28d635-7bec-4e78-b1c7-eddaab684e64"], "94196339-1259-4f23-9499-e7cac5296891": ["32401554-2713-4b19-8fce-be690dc2440f"], "24fc7ea1-a200-4877-8152-a59bd8bfd2f2": ["32401554-2713-4b19-8fce-be690dc2440f"], "174eea55-9655-4648-8a54-43ea96981ae0": ["32401554-2713-4b19-8fce-be690dc2440f"], "1c3c9cf9-d16a-4331-bf7a-b664a3b96e7f": ["32401554-2713-4b19-8fce-be690dc2440f"], "b4180c01-98dd-469f-bbed-6866f8c4394e": ["9559608e-0f52-4382-9da5-ce27deeec6d5"], "d7ea2e2e-13f5-42a1-881f-9a90c07ece3d": ["9559608e-0f52-4382-9da5-ce27deeec6d5"], "445a242f-e816-4fbf-8afa-bb71c927f032": ["9559608e-0f52-4382-9da5-ce27deeec6d5"], "6349548e-6d72-49cb-9013-4d9ca1b68a68": ["9559608e-0f52-4382-9da5-ce27deeec6d5"], "dd0626ab-2128-418a-9fd0-434f69f547e8": ["2e7a008c-4fea-42ff-b494-d4e0b0f31f29"], "13b8983e-7aa1-481e-acee-a985e74236a9": ["2e7a008c-4fea-42ff-b494-d4e0b0f31f29"], "b735f4ae-68c7-4c15-a7ec-dd09674ff043": ["2e7a008c-4fea-42ff-b494-d4e0b0f31f29"], "ec4ae2a9-fb83-480c-a0f4-dd04b76b89f8": ["2e7a008c-4fea-42ff-b494-d4e0b0f31f29"], "9455cd0f-5033-48ed-aeb9-ddd0ed89f2eb": ["175b8fb2-ae40-449c-86a4-45c915b9a5b4"], "da8084e8-caec-4091-bfa4-409cf03e360d": ["175b8fb2-ae40-449c-86a4-45c915b9a5b4"], "9cb51f32-7712-4129-93be-87fcf363d3ce": ["175b8fb2-ae40-449c-86a4-45c915b9a5b4"], "d86bae3c-b1c9-41cc-9b1a-3c864ba825b5": ["175b8fb2-ae40-449c-86a4-45c915b9a5b4"], "c9be5272-f319-4a87-8fec-d3d0b890e609": ["86130f66-65c9-4b35-9c41-f15bd8f4e8c4"], "58e0e619-72c8-46a8-9ea6-d9121a1e6f18": ["86130f66-65c9-4b35-9c41-f15bd8f4e8c4"], "c4944994-f37b-403e-8749-6709d6fc22ae": ["86130f66-65c9-4b35-9c41-f15bd8f4e8c4"], "4dac1631-5d16-4fbf-831a-393b08ad6797": ["86130f66-65c9-4b35-9c41-f15bd8f4e8c4"], "25069657-5fec-448e-b7fb-4afebcdf2d62": ["9799b9cb-9d25-4d1e-ab76-a343e6677073"], "73983ec8-2861-4ef2-a9ad-7ba707a13999": ["9799b9cb-9d25-4d1e-ab76-a343e6677073"], "5cbace73-3ec9-4dc2-be2a-6908ea1ae481": ["9799b9cb-9d25-4d1e-ab76-a343e6677073"], "cc69fbc7-e24c-48dd-a148-0da7c3a0eb08": ["9799b9cb-9d25-4d1e-ab76-a343e6677073"], "1d806264-08d9-4ef6-8d96-e879f3408d38": ["9b5cfa7a-203f-4454-9299-12f400927eca"], "d2e967db-281c-423d-b967-12e77d7c4ad1": ["9b5cfa7a-203f-4454-9299-12f400927eca"], "4185575d-814b-4a9a-9944-72a1e21d242e": ["9b5cfa7a-203f-4454-9299-12f400927eca"], "229f71e0-675b-49ab-81fb-d7c9bd7701e3": ["9b5cfa7a-203f-4454-9299-12f400927eca"], "b54a48d6-650b-4b70-bd1b-de661f691143": ["69bda2e7-4eb8-404e-89f6-f5765db39b58"], "3f7608eb-738b-4474-8c67-c0c134f5fc1b": ["69bda2e7-4eb8-404e-89f6-f5765db39b58"], "a231b07d-0bb7-40e6-93a9-c83d33b05c8b": ["81a37398-de59-4161-8b06-a9f39efe9d12"], "b80023c9-e0ab-47d8-9348-96d27b72b659": ["81a37398-de59-4161-8b06-a9f39efe9d12"], "89cf87ad-7b0c-4e4c-8daa-4d7b0bbc9730": ["81a37398-de59-4161-8b06-a9f39efe9d12"], "c99b7625-150e-4659-865c-65236e544e67": ["81a37398-de59-4161-8b06-a9f39efe9d12"], "c2ebb62c-652a-4225-803e-eb7c12a1604e": ["21c03bab-8f76-40c1-a4db-daf7820d7d06"], "d30313cf-d634-4907-85dc-3950697280ba": ["21c03bab-8f76-40c1-a4db-daf7820d7d06"], "263f5e6f-295c-4a90-abfc-edac9ed99c93": ["ad1113e4-2406-44ff-afb6-983cab194be6"], "8a657ca9-1f3e-4644-89ef-9fd6c5a765a9": ["ad1113e4-2406-44ff-afb6-983cab194be6"], "35888ba5-13c6-409a-9cd9-1bf296b39f6c": ["ad1113e4-2406-44ff-afb6-983cab194be6"], "b94aa6bc-7523-44ea-9562-bccc5f543847": ["ad1113e4-2406-44ff-afb6-983cab194be6"], "a45533d0-5ff8-476e-9408-291f2d681258": ["bd2b237f-8ab8-4f8e-9d14-18770e142166"], "8d81a741-7548-4f95-bcae-eeb1527d9e9f": ["bd2b237f-8ab8-4f8e-9d14-18770e142166"], "840fa455-4398-4d64-9f5a-18c9d2cfeadf": ["bd2b237f-8ab8-4f8e-9d14-18770e142166"], "cbf729d2-eb59-4584-87f9-c7d1f58c7537": ["bd2b237f-8ab8-4f8e-9d14-18770e142166"], "d5866311-3146-47bb-9c90-91040fcc9437": ["919ae4c0-da0b-4c41-a1ec-bce7a57c97dd"], "64701e65-5c61-466c-beae-dc5591e8a9ac": ["919ae4c0-da0b-4c41-a1ec-bce7a57c97dd"], "87013628-c827-420f-9960-e70a73f0104c": ["919ae4c0-da0b-4c41-a1ec-bce7a57c97dd"], "5dd811e5-bad3-4005-bb31-a8c5903e182a": ["919ae4c0-da0b-4c41-a1ec-bce7a57c97dd"], "50765201-41ce-4883-9d1b-893b66893582": ["6832b372-be19-4210-8316-26235d594358"], "c379be47-7a50-4b84-85cf-b2740570980d": ["6832b372-be19-4210-8316-26235d594358"], "b59d1620-8263-4aa8-86cb-149e50aa4546": ["6832b372-be19-4210-8316-26235d594358"], "b800a018-3d8c-46eb-869d-2f41acd73b94": ["6832b372-be19-4210-8316-26235d594358"], "c55cb37a-58d7-45b8-92f3-74f1f2c5fd9b": ["3f2b94aa-0bc3-44a5-8cd2-b9e76a72af62"], "294b5c76-b87a-4a50-aafa-24f7fc1c77ea": ["3f2b94aa-0bc3-44a5-8cd2-b9e76a72af62"], "0c1b143c-4831-4617-a1e5-959e2f0dc0a5": ["3f2b94aa-0bc3-44a5-8cd2-b9e76a72af62"], "5cda5afb-a89a-4109-837e-64465f8945a2": ["3f2b94aa-0bc3-44a5-8cd2-b9e76a72af62"], "c15fe6ba-4fbf-4ee3-9ee3-bdd3c9bcfe78": ["600a9f5b-1894-4c98-82cb-aacb89ab3916"], "ccb9a89b-36a1-4b23-8f1e-3521a4727d70": ["600a9f5b-1894-4c98-82cb-aacb89ab3916"], "3884a5b9-eec7-4945-8153-d9285841bb64": ["600a9f5b-1894-4c98-82cb-aacb89ab3916"], "1a3e384c-6ee3-4bba-ad5f-b2c767f35787": ["600a9f5b-1894-4c98-82cb-aacb89ab3916"], "ff2f4ae6-d936-46c1-9f9b-f098f9e57b5d": ["ff054c37-f20e-468b-ac39-a67ba9679861"], "336757a9-8910-46be-b023-8bf3d73dd443": ["ff054c37-f20e-468b-ac39-a67ba9679861"], "c6dec6a8-d832-4b95-86e9-491821434a10": ["ff054c37-f20e-468b-ac39-a67ba9679861"], "84df49e7-848f-4df3-aeec-3cd57c4b8489": ["ff054c37-f20e-468b-ac39-a67ba9679861"], "5138d00d-a477-41ec-87d7-9f49d3949360": ["a4f78942-0ecf-40c7-951d-9d00f644376e"], "878036e5-0a98-45e6-bc9a-41dd31cf0fed": ["a4f78942-0ecf-40c7-951d-9d00f644376e"], "73c13380-0917-4b49-b762-7afeda48f36b": ["a4f78942-0ecf-40c7-951d-9d00f644376e"], "88b67fd8-5bb0-4c84-a93c-36c4c516be0e": ["a4f78942-0ecf-40c7-951d-9d00f644376e"], "e467f192-15b8-43f9-b8a7-e710e55454d1": ["60fae91c-fb0d-43a4-ae72-2c94d7af85d9"], "418318a5-a227-4bc5-ac20-68432d0c8549": ["60fae91c-fb0d-43a4-ae72-2c94d7af85d9"], "2bb34a22-78ed-4947-9ab6-e346da822b12": ["60fae91c-fb0d-43a4-ae72-2c94d7af85d9"], "cef00f8b-378c-4056-818e-39c6a0844cc8": ["60fae91c-fb0d-43a4-ae72-2c94d7af85d9"], "23d4bb76-8cc2-46c2-bb3e-2919ac86498f": ["ed168f03-ea73-41cb-9e6c-a16f846e4a82"], "ba00aa50-f001-4711-8c46-a9e4eb115c9c": ["ed168f03-ea73-41cb-9e6c-a16f846e4a82"], "426b77bd-5da5-4a6d-8c42-23a0355e8d8a": ["5aa6d22b-5969-4b16-950f-e117c1925152"], "c7cbca2b-8284-494f-80a3-cc80310ef8e2": ["5aa6d22b-5969-4b16-950f-e117c1925152"], "be62725c-7116-4f16-b588-d44dd7c99004": ["2f1e950d-e5ba-4238-988d-d9f85bdc1796"], "4eb29041-ec8f-4e04-814a-ab0fc28df84f": ["2f1e950d-e5ba-4238-988d-d9f85bdc1796"], "d56a8031-bc7a-4172-b4ad-e8e92977c851": ["2f1e950d-e5ba-4238-988d-d9f85bdc1796"], "3651e377-3961-4287-8c67-e3fa6475a5e0": ["2f1e950d-e5ba-4238-988d-d9f85bdc1796"], "fc3ded65-9500-48ce-af03-a4682acdb521": ["e39608bc-5563-482b-b6db-54105c000365"], "86e048a4-ee0d-4aa2-86ab-4920d91e0dab": ["e39608bc-5563-482b-b6db-54105c000365"], "3cd46f5b-a1c9-4d08-b414-54da3a1a482e": ["e39608bc-5563-482b-b6db-54105c000365"], "68c10021-6d1d-43c9-8abc-27ab0c93c555": ["e39608bc-5563-482b-b6db-54105c000365"], "9708b6b4-c540-470a-bce6-79a780de48df": ["f1fdee30-73a4-41eb-926b-d6c9a7b55c17"], "2e199d16-321c-4092-8f4b-c9e5cbda50ff": ["f1fdee30-73a4-41eb-926b-d6c9a7b55c17"], "40d631e8-bc35-4e7e-83f1-a7c24fe8225b": ["f1fdee30-73a4-41eb-926b-d6c9a7b55c17"], "52403542-3ecc-483a-ab63-4ddb71c8edcc": ["f1fdee30-73a4-41eb-926b-d6c9a7b55c17"], "0cde4351-66b8-4c27-89b5-1d4dfb605257": ["cf2f8503-367e-464d-8f56-3745b610d190"], "b8270166-e996-428f-af0c-3b65199f899a": ["cf2f8503-367e-464d-8f56-3745b610d190"], "c97c6990-659d-461e-86e5-48c17c068c68": ["cf2f8503-367e-464d-8f56-3745b610d190"], "cebd050c-83b1-40b6-a5f1-9bd874f9fa18": ["cf2f8503-367e-464d-8f56-3745b610d190"], "dc529af4-2a10-4c8d-8ae1-76eb428aabc1": ["2b5bd0d2-6115-4768-9c50-b6633b361123"], "8e4a280f-3dc4-41d7-adf2-111095ead9a1": ["2b5bd0d2-6115-4768-9c50-b6633b361123"], "b0a4565e-d65f-49a7-a71d-54c7a146ba27": ["2b5bd0d2-6115-4768-9c50-b6633b361123"], "e2d2776f-def6-49bc-bea4-74b099c121a1": ["2b5bd0d2-6115-4768-9c50-b6633b361123"], "e92cc911-6ca2-4a66-8351-6a995a0d7855": ["0a2ffa56-da87-4c24-af0b-9d0b2a09d911"], "1d198f50-2834-4086-acd7-81406ab32890": ["0a2ffa56-da87-4c24-af0b-9d0b2a09d911"], "f35938c1-510a-4ad8-a0a7-79423f1bca0d": ["0a2ffa56-da87-4c24-af0b-9d0b2a09d911"], "f132833b-8c46-45b6-a0db-59712743c219": ["0a2ffa56-da87-4c24-af0b-9d0b2a09d911"], "89df69e3-302b-4a99-896d-038b6318baaf": ["bcd976fc-15e7-439b-9416-be67bd166962"], "7d2750ef-78b5-4f22-a763-7a2e1c30303d": ["bcd976fc-15e7-439b-9416-be67bd166962"], "f879ccbb-55e4-4967-9ccb-6541caffcd44": ["bcd976fc-15e7-439b-9416-be67bd166962"], "b67d3df0-cb55-40c6-8716-15e5973932b5": ["bcd976fc-15e7-439b-9416-be67bd166962"], "4329f2fc-325a-4d16-98d7-5dc535a32502": ["619a18d9-6b7a-4475-bdea-0378010a7bde"], "afd1e6e7-1adf-47a1-9a7d-8435fceea515": ["619a18d9-6b7a-4475-bdea-0378010a7bde"], "55d83188-0a12-4255-a75b-2b761e0b7ea9": ["619a18d9-6b7a-4475-bdea-0378010a7bde"], "23620a20-d46a-461a-8ff5-f8ff2dc54978": ["619a18d9-6b7a-4475-bdea-0378010a7bde"], "3d83f357-a428-4c9a-89cb-e0d88db2fc77": ["6baa83e7-69a9-45ff-9b25-12af80fa6d74"], "3f4c58e2-3bc1-4be8-a415-0755ae2707d2": ["6baa83e7-69a9-45ff-9b25-12af80fa6d74"], "4ef79349-1e07-419b-9fbd-525d56c84973": ["6baa83e7-69a9-45ff-9b25-12af80fa6d74"], "b4f72b3d-984e-49d3-8261-1fbe5fd3e714": ["6baa83e7-69a9-45ff-9b25-12af80fa6d74"], "a2592a8a-95e7-4be7-84b6-fd36d1f57a32": ["d5c8d5cb-49f6-445c-9084-4fe8f45b64aa"], "2e6c2721-9d83-421a-82fa-16bf4346e97d": ["d5c8d5cb-49f6-445c-9084-4fe8f45b64aa"], "21026bc7-0f4c-417b-bd00-eaeb4c7d47f1": ["a0c498f6-5c4d-42f7-9b7b-1d1a0a63a8ee"], "641c0088-5fde-4243-88c2-2cfff9b2e4d8": ["a0c498f6-5c4d-42f7-9b7b-1d1a0a63a8ee"], "65c6bbcd-476b-4592-84fe-f003589e1cc9": ["a0c498f6-5c4d-42f7-9b7b-1d1a0a63a8ee"], "30ce6bad-9500-4dda-9a9c-5f30e4022761": ["a0c498f6-5c4d-42f7-9b7b-1d1a0a63a8ee"], "fdad1781-d98d-408a-b2d0-762cab9f3b1f": ["75ce678d-2b12-4e93-b97c-f28ec3bdeb50"], "fc1578ea-ef2f-4ec3-b088-b74c9a7e3372": ["75ce678d-2b12-4e93-b97c-f28ec3bdeb50"], "c832e829-56c7-4483-81af-bdfe328c5e9b": ["cd76727a-504a-46a7-8fce-f54722ebd46d"], "c096ee40-6015-4587-a5e8-3c30410cdc83": ["cd76727a-504a-46a7-8fce-f54722ebd46d"], "f67ea233-1373-448c-b3e1-a2f4dd01217f": ["41fe1bef-7eb9-410f-bc2e-5fa2d1e20245"], "8412ef09-0bb0-4ab0-9743-e0be5d2040e5": ["41fe1bef-7eb9-410f-bc2e-5fa2d1e20245"], "141981c1-eb69-4b39-aad6-75f2b8c43537": ["41fe1bef-7eb9-410f-bc2e-5fa2d1e20245"], "bb70c549-cc87-4ece-9056-8d1d6d233c0b": ["41fe1bef-7eb9-410f-bc2e-5fa2d1e20245"], "a9fb34d4-3049-4b8a-986b-12e8d2391c30": ["3f0e9786-de4e-451b-86f9-f9d9b79589a4"], "bc72beb0-c926-428d-9998-f2c28bf28ecc": ["3f0e9786-de4e-451b-86f9-f9d9b79589a4"], "b7c175a3-86d8-47cc-a4bf-377eef5c5261": ["3f0e9786-de4e-451b-86f9-f9d9b79589a4"], "129c2aab-9911-4955-a528-cd260166ced4": ["3f0e9786-de4e-451b-86f9-f9d9b79589a4"], "c66bca39-6958-477b-a7bd-f5408c173c26": ["5e0dd80b-a7b0-4751-80ba-93b00e981bbb"], "dda837ca-a996-4c43-b448-488f97d5e602": ["5e0dd80b-a7b0-4751-80ba-93b00e981bbb"], "28fff0fe-cec6-4dcd-b86f-d40cde7075fb": ["5dee00d6-ebe0-4332-9e92-d1c8d4d6196e"], "7ad1c918-3ae5-4e4c-ae69-c677f97fb797": ["5dee00d6-ebe0-4332-9e92-d1c8d4d6196e"], "7308d0a3-08c7-4ed8-a1c6-ef68fd55405a": ["5dee00d6-ebe0-4332-9e92-d1c8d4d6196e"], "018d0329-3c42-4a9f-ac7b-2aecf199e7e4": ["5dee00d6-ebe0-4332-9e92-d1c8d4d6196e"], "a50e7d23-6aa0-4fc0-af98-9e0a6b184339": ["bf103488-d02f-435a-a103-eae5fb372cbf"], "62313af3-e445-41a1-82cc-371b6f8a5376": ["bf103488-d02f-435a-a103-eae5fb372cbf"], "15130afc-8fc4-4e0d-bf93-c5b844d9726f": ["bf103488-d02f-435a-a103-eae5fb372cbf"], "4fe36d59-e848-43ae-a01e-03730e59ef9e": ["bf103488-d02f-435a-a103-eae5fb372cbf"], "eba91ce5-88ba-401f-87d0-9227d3b71179": ["32bd0835-c059-46a2-95a8-4faf8ca96364"], "b2b8ece6-8c2b-4353-b0f6-35de5a09fa8c": ["32bd0835-c059-46a2-95a8-4faf8ca96364"], "71c2e842-0b32-44cd-8a91-2fb0366d5892": ["32bd0835-c059-46a2-95a8-4faf8ca96364"], "fa6a7393-9970-4980-af8d-068b3370a14c": ["32bd0835-c059-46a2-95a8-4faf8ca96364"], "84634ce9-f22e-48f7-b4dd-743b89bace80": ["1ed941fc-e5d0-487a-a407-9fd882b669ff"], "9f098ff2-8ec3-49f0-a070-12da0c1dd3c5": ["1ed941fc-e5d0-487a-a407-9fd882b669ff"], "41fcfd5c-3bb0-4abf-8871-c7e60541e49b": ["1ed941fc-e5d0-487a-a407-9fd882b669ff"], "2bccdf2f-466c-4a07-8b5d-94c3ff9ac40c": ["1ed941fc-e5d0-487a-a407-9fd882b669ff"], "107d0054-6589-4c39-8f6b-a0b6ede62629": ["166a1ff3-2545-4162-94a2-4d87a76cb511"], "a67215c5-4a67-4c81-b2c2-f3a9dc2fcedc": ["166a1ff3-2545-4162-94a2-4d87a76cb511"], "dec724bd-34c8-4710-9fab-034de7174f0f": ["166a1ff3-2545-4162-94a2-4d87a76cb511"], "c4f1e408-bb68-41ab-b70e-d12a6c211000": ["166a1ff3-2545-4162-94a2-4d87a76cb511"], "b529f089-e589-46f2-9564-7be083229870": ["d4f3d439-cd2a-4f63-acb0-c18a98e413dd"], "1fe35594-9ada-4e9f-b518-f7ab0ef49596": ["d4f3d439-cd2a-4f63-acb0-c18a98e413dd"], "b1367d10-da3b-4341-9c79-1f494c47e08f": ["d4f3d439-cd2a-4f63-acb0-c18a98e413dd"], "769b2544-9c9f-4c54-97a0-56b0c69274ce": ["d4f3d439-cd2a-4f63-acb0-c18a98e413dd"], "5d150d61-872b-4d0c-ab98-f97f81d10cff": ["ae5d2160-3d22-4d4c-9164-a9fab5903313"], "28a5723e-7531-4712-bd59-09d7b2523c4b": ["ae5d2160-3d22-4d4c-9164-a9fab5903313"], "3a744455-161f-4493-9039-cdade96697c9": ["ae5d2160-3d22-4d4c-9164-a9fab5903313"], "758ff43c-4a3f-4165-8c4c-aac3da1803bf": ["ae5d2160-3d22-4d4c-9164-a9fab5903313"], "3baa5994-456a-473c-9cad-6771b7ecfa2f": ["96a969b8-7acc-45a3-9762-f972be98687a"], "dedbefbc-5622-4889-813e-d9dc45eaebea": ["96a969b8-7acc-45a3-9762-f972be98687a"], "0dc10ac9-f689-4101-9369-f70ecb294238": ["96a969b8-7acc-45a3-9762-f972be98687a"], "4738a635-d3fb-49fa-9c2e-5794ff314ca8": ["96a969b8-7acc-45a3-9762-f972be98687a"], "7da7e5a7-0260-45ff-b401-0a61ee1c57f7": ["95b025e2-e9cb-4109-9d20-5f5160c8ee7e"], "8b3a431f-f875-43df-9e68-fe944304d5f1": ["95b025e2-e9cb-4109-9d20-5f5160c8ee7e"], "8ee1ad98-4f55-40d8-a099-e721bf76426c": ["95b025e2-e9cb-4109-9d20-5f5160c8ee7e"], "eb66e765-1f9b-4237-a6dd-6f95843fec55": ["95b025e2-e9cb-4109-9d20-5f5160c8ee7e"], "f4ff9b0d-9d41-417a-88c2-937ea0b8bf76": ["de6dd0fa-2b68-4404-a274-49c64922cc63"], "1c28405a-5c72-47dd-87dc-e1cfe12f81ba": ["de6dd0fa-2b68-4404-a274-49c64922cc63"], "f2195d18-bc21-47e8-a471-04200290571b": ["de6dd0fa-2b68-4404-a274-49c64922cc63"], "9443c53c-4650-487f-932b-e25d135268e6": ["de6dd0fa-2b68-4404-a274-49c64922cc63"], "37d384ee-da11-41af-a69e-6eab911ab378": ["055e6d8f-2d7a-4bd4-922d-5192f25567af"], "4fb8771f-ad91-4d00-bff3-a7ede207ab34": ["055e6d8f-2d7a-4bd4-922d-5192f25567af"], "5adfb3ff-b59f-4901-9261-f78522ca216e": ["055e6d8f-2d7a-4bd4-922d-5192f25567af"], "df20511b-1c06-43e6-84ab-e5ee7d8d0a93": ["055e6d8f-2d7a-4bd4-922d-5192f25567af"], "c5cdd213-ac1d-4fb7-965b-ce6a3d5d0fff": ["57496c11-f07e-436e-a7ba-a32d44a4a4e4"], "ca066e8d-fe94-47ba-afba-59e1869dd181": ["57496c11-f07e-436e-a7ba-a32d44a4a4e4"], "cb5e7558-6de9-451b-a9fe-7a7ba2744e17": ["57496c11-f07e-436e-a7ba-a32d44a4a4e4"], "9d89ca83-8b07-4f46-9a03-fb250add5ba1": ["57496c11-f07e-436e-a7ba-a32d44a4a4e4"], "f647186a-8e31-4847-8711-3bc72d709bc5": ["5cf465b7-6b2a-4fd9-9430-2209da8d49b0"], "ce4ab675-887e-4f34-a2d4-59b635194483": ["5cf465b7-6b2a-4fd9-9430-2209da8d49b0"], "7e52f4b0-507f-4496-bf0a-ab78bf2565e4": ["5cf465b7-6b2a-4fd9-9430-2209da8d49b0"], "ae1205b5-3c75-4152-8524-98d7e6049d35": ["5cf465b7-6b2a-4fd9-9430-2209da8d49b0"], "0ded3534-521f-4cb3-8ed5-2b0a82dd6d29": ["f4ec47a4-3267-4159-81db-006b587cef15"], "f7055319-5aba-45fe-b98e-b492323294e4": ["f4ec47a4-3267-4159-81db-006b587cef15"], "dc6f9018-25cd-40dc-a593-182ff992641d": ["f4ec47a4-3267-4159-81db-006b587cef15"], "810a07f8-e66e-417f-876b-ed8f248f5a90": ["f4ec47a4-3267-4159-81db-006b587cef15"], "82df5139-78c3-4ed5-8e37-aa90f66934c0": ["92b1bb40-1869-4933-97b5-d4e9d8df16f4"], "fc67e339-1216-4ab5-ac34-16ff6e665105": ["92b1bb40-1869-4933-97b5-d4e9d8df16f4"], "aa8f0ebd-2c6f-4860-a07f-da00055bdbcd": ["92b1bb40-1869-4933-97b5-d4e9d8df16f4"], "942c8636-6a6b-408b-8794-c2994bada9af": ["92b1bb40-1869-4933-97b5-d4e9d8df16f4"], "261e58fd-1c8b-493d-b2d2-4fba898410ad": ["c398eff3-c505-4ee5-b480-528e2c488b41"], "b7c1e280-0c57-434a-afd8-30f6473ec963": ["c398eff3-c505-4ee5-b480-528e2c488b41"], "dff66871-4063-476e-bb54-190986756137": ["c398eff3-c505-4ee5-b480-528e2c488b41"], "960f3f37-54d6-497c-8c7c-335f3b40499c": ["c398eff3-c505-4ee5-b480-528e2c488b41"], "cc611f91-7e7f-4c95-9954-6ff6273e23f0": ["a66b1f7f-f93e-475b-981e-ddd14a9f8bfe"], "3fa35071-9398-470d-9986-b9a01f232f8a": ["a66b1f7f-f93e-475b-981e-ddd14a9f8bfe"], "f9a6a704-a37f-458c-9cb7-07a4ae56e307": ["a66b1f7f-f93e-475b-981e-ddd14a9f8bfe"], "0181ef15-2ce1-45eb-947b-aa9eca492f87": ["a66b1f7f-f93e-475b-981e-ddd14a9f8bfe"], "c2b7ea50-c446-4749-acaf-6587ec5af94b": ["de4eebaf-00d4-4a70-9415-d2599c78e152"], "23b520a4-d7ad-42f9-b417-33c6c3b48de4": ["de4eebaf-00d4-4a70-9415-d2599c78e152"], "93aeb3d7-c716-4613-a0b4-82840308e301": ["de4eebaf-00d4-4a70-9415-d2599c78e152"], "8248663f-7443-400a-a4eb-201b0227c547": ["de4eebaf-00d4-4a70-9415-d2599c78e152"], "5f557a45-ad35-480c-86da-6dc2a7a4ea0b": ["873ebb99-96ec-4432-baa8-db54fcea594a"], "bb249340-4c46-44d2-a37b-8194c642b33b": ["873ebb99-96ec-4432-baa8-db54fcea594a"], "b65c1e76-ebf8-4f2b-b989-46968cb58b37": ["873ebb99-96ec-4432-baa8-db54fcea594a"], "0dbdf213-0ee3-40cc-ab18-30c2be136351": ["873ebb99-96ec-4432-baa8-db54fcea594a"], "4cd1dd4a-6614-45b3-b67b-133b27dd4b09": ["d2deaa99-4a98-437c-8d51-35567ce363a4"], "86626d8e-212f-4ada-aa14-99be48a832f0": ["d2deaa99-4a98-437c-8d51-35567ce363a4"], "4479043a-ba20-455c-ba8b-20b21d76032c": ["d2deaa99-4a98-437c-8d51-35567ce363a4"], "e12e46e6-b94b-4ab5-b306-868830589575": ["d2deaa99-4a98-437c-8d51-35567ce363a4"], "f7c18978-06ec-4f03-9cbb-7c419eb5004f": ["a7055094-2b48-4a9e-80cd-0e22bb8ee792"], "44b8b7c0-614d-43d7-af50-f6fa1baf14de": ["a7055094-2b48-4a9e-80cd-0e22bb8ee792"], "2d118a5a-a5cc-4a1f-99f6-239e0d33f7d4": ["a7055094-2b48-4a9e-80cd-0e22bb8ee792"], "6153f124-2754-4aff-afb1-e75b84a539b4": ["a7055094-2b48-4a9e-80cd-0e22bb8ee792"], "76be9d18-9309-4719-be0b-934a906d9841": ["0dad068e-fe94-4766-bb83-00b6a2495660"], "dcd16b1c-03e1-4ee8-a590-f553b58d454a": ["0dad068e-fe94-4766-bb83-00b6a2495660"], "d96d3b44-863d-4785-ac36-35381f75efa2": ["1a882493-7650-4e79-a923-985429d657db"], "8307cc9e-e5bb-4fc0-9b00-9347db56c399": ["1a882493-7650-4e79-a923-985429d657db"], "ee9257bb-4e2e-4543-8611-7130a9636d70": ["1a882493-7650-4e79-a923-985429d657db"], "29875337-5236-4de5-9675-2125735889ac": ["1a882493-7650-4e79-a923-985429d657db"], "b0123edd-2fdd-4226-be6f-ea2d4b53b7be": ["6dfda473-ae4a-4b36-8d04-de360fc328f2"], "0c50d46d-3d90-40f2-a2dc-bb2c813747ad": ["6dfda473-ae4a-4b36-8d04-de360fc328f2"], "97ea6cef-a458-43b2-a780-ff378a19fa64": ["6dfda473-ae4a-4b36-8d04-de360fc328f2"], "44d9846d-c4cc-440c-bc0b-b3b6b5f75f9e": ["6dfda473-ae4a-4b36-8d04-de360fc328f2"], "091c9326-1b12-42f0-af6d-ed868fc51dfa": ["0c5a7874-73d5-4e5c-842c-bf5f9a8d788f"], "ab21d9cb-72ed-4d96-9a1e-a654ece91083": ["0c5a7874-73d5-4e5c-842c-bf5f9a8d788f"], "e85559ad-7074-4646-9702-77b3150f13d8": ["0c5a7874-73d5-4e5c-842c-bf5f9a8d788f"], "e0500759-8ad1-4935-8c6b-553cb13ffe84": ["0c5a7874-73d5-4e5c-842c-bf5f9a8d788f"], "42bd5103-864a-4f19-b194-70e62441c618": ["b8574b97-a230-44a3-b087-154a6273d7d2"], "02dc437e-2e92-4a89-8292-94b8e80d71f4": ["b8574b97-a230-44a3-b087-154a6273d7d2"], "6f8a60e2-ed27-4c22-ae1c-95f98a178632": ["b8574b97-a230-44a3-b087-154a6273d7d2"], "3038ff4c-44f4-4cb6-9055-4bf022a1fa87": ["b8574b97-a230-44a3-b087-154a6273d7d2"], "a6ecb07a-9a5c-4163-a7fd-91c529854dd9": ["be8491a3-5d2b-45e3-b3dc-c28721fc8a08"], "4f9b48f9-19f0-4f1e-9bd4-0a555fa50c71": ["be8491a3-5d2b-45e3-b3dc-c28721fc8a08"], "b093df04-3637-4035-bb2a-787269daeef2": ["be8491a3-5d2b-45e3-b3dc-c28721fc8a08"], "7f44c093-2ce5-4fc5-a116-73608ef11d65": ["be8491a3-5d2b-45e3-b3dc-c28721fc8a08"], "64113107-e2b9-4309-b2cf-0bff76f67537": ["f0dfc1e4-609c-49a9-a8ab-a6853ff84475"], "f1848890-85ce-4fdc-98eb-183bb7a2923a": ["f0dfc1e4-609c-49a9-a8ab-a6853ff84475"], "122fb62c-ab2b-4646-af2b-a830aead3697": ["f0dfc1e4-609c-49a9-a8ab-a6853ff84475"], "e8031301-5238-4a7b-bb65-1ffb930ad52e": ["f0dfc1e4-609c-49a9-a8ab-a6853ff84475"], "28c890ad-a28a-48e5-a89b-4af4c7950545": ["06ccbec0-039e-4e05-abf6-83c71c07c33b"], "1a287c09-e164-4c43-930e-08f8b4cb8e37": ["06ccbec0-039e-4e05-abf6-83c71c07c33b"], "fecfe119-aa9d-47a1-8a2a-15c5adc2bb45": ["06ccbec0-039e-4e05-abf6-83c71c07c33b"], "131e2486-fc9f-400e-a2e3-887146a48af6": ["06ccbec0-039e-4e05-abf6-83c71c07c33b"], "bb84b0d2-8968-42f8-879d-f30fd7dd943f": ["cf960004-acca-4b68-8bbb-6adbafa3512c"], "06a4860c-4f39-4cf6-84a0-bafa9d12ebe4": ["cf960004-acca-4b68-8bbb-6adbafa3512c"], "d31bb84a-6b27-4d38-a3ad-0d45ddfe12b0": ["cf960004-acca-4b68-8bbb-6adbafa3512c"], "a6c6a875-ddd2-4bd7-b4a5-32dc20038aab": ["cf960004-acca-4b68-8bbb-6adbafa3512c"], "d8dd4bf4-bbb7-49b9-aeba-4699b08ecb48": ["1d620e05-66e1-47ae-b2cc-5a979cca95e3"], "76b4b149-73c5-454c-9e67-df31fc33d963": ["1d620e05-66e1-47ae-b2cc-5a979cca95e3"], "1c5071e6-7a92-46f8-a305-06839bf1a6f6": ["1d620e05-66e1-47ae-b2cc-5a979cca95e3"], "950f1c4d-fcf2-45f9-9e33-e147f43f730c": ["1d620e05-66e1-47ae-b2cc-5a979cca95e3"], "f48826e5-05c7-47cd-9db8-9a8e8ec9fc3b": ["7d627f5a-4a32-4b77-a531-7a755d146f9e"], "aba8283d-8aef-4988-874d-726f80c91979": ["7d627f5a-4a32-4b77-a531-7a755d146f9e"], "2d7ec6ec-9463-40b2-9fc6-8b39651b0852": ["4197d166-2cc8-43b3-ab81-c405d2175422"], "b8b67056-b0d1-444c-aed3-9acdecd788c6": ["4197d166-2cc8-43b3-ab81-c405d2175422"], "428942cd-286f-4fe0-84f6-6cc806d66a15": ["4197d166-2cc8-43b3-ab81-c405d2175422"], "c61b5e78-d685-4a99-9912-b2759d64a5cb": ["4197d166-2cc8-43b3-ab81-c405d2175422"], "e9c21a42-5c78-430f-870a-a4ee43e31796": ["a042fa5b-43b0-489e-9af7-56857671fbf3"], "af34ef70-06be-4c65-8855-b23e4c3b4e88": ["a042fa5b-43b0-489e-9af7-56857671fbf3"]}, "corpus": {"2a265a8c-5ff0-44e0-9b1a-a125367ebdc6": "Stuff we figured out about AI in 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimon Willison\u2019s Weblog\nSubscribe\n\n\n\n\n\n\nStuff we figured out about AI in 2023\n31st December 2023\n2023 was the breakthrough year for Large Language Models (LLMs). I think it\u2019s OK to call these AI\u2014they\u2019re the latest and (currently) most interesting development in the academic field of Artificial Intelligence that dates back to the 1950s.\nHere\u2019s my attempt to round up the highlights in one place!", "a79767c8-f778-4cb5-b3d3-685a1d16b398": "Large Language Models\nThey\u2019re actually quite easy to build\nYou can run LLMs on your own devices\nHobbyists can build their own fine-tuned models\nWe don\u2019t yet know how to build GPT-4\nVibes Based Development\nLLMs are really smart, and also really, really dumb\nGullibility is the biggest unsolved problem\nCode may be the best application\nThe ethics of this space remain diabolically complex\nMy blog in 2023", "bd552d84-ad46-4694-9d55-dc7e1d72fc87": "Here\u2019s the sequel to this post: Things we learned about LLMs in 2024.\nLarge Language Models\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.", "4ae49088-dbc8-4cbd-9ea6-3ec8309ab431": "So far, I think they\u2019re a net positive. I\u2019ve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.\nA lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity.\nThey\u2019re actually quite easy to build\nThe most surprising thing we\u2019ve learned about LLMs this year is that they\u2019re actually quite easy to build.", "9bd61495-3eb9-46e8-b21b-1e15e2f9a7c2": "Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\nWhat matters most is the training  data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.", "5386e9bd-322e-48d3-8231-c5d66a10f1e4": "A year ago, the only organization that had released a generally useful LLM was OpenAI. We\u2019ve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\nThe training cost (hardware and electricity) is still significant\u2014initially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft\u2019s Phi-2 claims to have used \u201c14 days on 96 A100 GPUs\u201d, which works out at around $35,000 using current Lambda pricing.", "1c28d635-7bec-4e78-b1c7-eddaab684e64": "So training an LLM still isn\u2019t something a hobbyist can afford, but it\u2019s no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge\u2014not trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia\u2019s Suspension bridges by country category lists 44 countries).\nYou can run LLMs on your own devices\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.", "32401554-2713-4b19-8fce-be690dc2440f": "Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!\nThis unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2\u2014an improved version which, crucially, included permission for commercial use.\nToday there are literally thousands of LLMs that can be run locally, on all manner of different devices.", "9559608e-0f52-4382-9da5-ce27deeec6d5": "I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins.\nYou can even run them entirely in your browser using WebAssembly and the latest Chrome!\nHobbyists can build their own fine-tuned models\nI said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely.", "2e7a008c-4fea-42ff-b494-d4e0b0f31f29": "There\u2019s now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too.\nThe Hugging Face Open LLM Leaderboard is one place that tracks these. I can\u2019t even attempt to count them, and any count would be out-of-date within a few hours.\nThe best overall openly licensed LLM at any time is rarely a foundation model: instead, it\u2019s whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data.\nThis is a huge advantage for open over closed models: the closed, hosted models don\u2019t have thousands of researchers and hobbyists around the world collaborating and competing to improve them.", "175b8fb2-ae40-449c-86a4-45c915b9a5b4": "We don\u2019t yet know how to build GPT-4\nFrustratingly, despite the enormous leaps ahead we\u2019ve had this year, we are yet to see an alternative model that\u2019s better than GPT-4.\nOpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing.\nThis may well change in the next few weeks: Google\u2019s Gemini Ultra has big claims, but isn\u2019t yet available for us to try out.\nThe team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they\u2019ve released two significant improvements since then.", "86130f66-65c9-4b35-9c41-f15bd8f4e8c4": "Still, I\u2019m surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven\u2019t shared yet.\nVibes Based Development\nAs a computer scientist and software engineer, LLMs are infuriating.\nEven the openly licensed ones are still the world\u2019s most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them.\nI\u2019m used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that!\nThe worst part is the challenge of evaluating them.\nThere are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually \u201cfeels\u201d right when you try it for a given task.", "9799b9cb-9d25-4d1e-ab76-a343e6677073": "I find I have to work with an LLM for a few weeks in order to get a good intuition for it\u2019s strengths and weaknesses. This greatly limits how many I can evaluate myself!\nThe most frustrating thing for me is at the level of individual prompting.\nSometimes I\u2019ll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don\u2019t have a good methodology for figuring that out.\nWe\u2019re left with what\u2019s effectively Vibes Based Development. It\u2019s vibes all the way down.\nI\u2019d love to see us move beyond vibes in 2024!\nLLMs are really smart, and also really, really dumb", "9b5cfa7a-203f-4454-9299-12f400927eca": "On the one hand, we keep on finding new things that LLMs can do that we didn\u2019t expect\u2014and that the people who trained the models didn\u2019t expect either. That\u2019s usually really fun!\nBut on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb.\nDoes ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays?\nThe honest answer is \u201cmaybe\u201d! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer.", "69bda2e7-4eb8-404e-89f6-f5765db39b58": "Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can\u2019t type because you don\u2019t have any fingers it produces the full code for you instead.\nThere are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It\u2019s all so dumb, but it works!\nGullibility is the biggest unsolved problem\nI coined the term prompt injection in September last year.\n15 months later, I regret to say that we\u2019re still no closer to a robust, dependable solution to this problem.\nI\u2019ve written a ton about this already.\nBeyond that specific class of security vulnerabilities, I\u2019ve started seeing this as a wider problem of gullibility.", "81a37398-de59-4161-8b06-a9f39efe9d12": "Language Models are gullible. They \u201cbelieve\u201d what we tell them\u2014what\u2019s in their training data, then what\u2019s in the fine-tuning data, then what\u2019s in the prompt.\nIn order to be useful tools for us, we need them to believe what we feed them!\nBut it turns out a lot of the things we want to build need them not to be gullible.\nEveryone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited.", "21c03bab-8f76-40c1-a4db-daf7820d7d06": "A lot of people are excited about AI agents\u2014an infuriatingly vague term that seems to be converging on \u201cAI systems that can go away and act on your behalf\u201d. We\u2019ve been talking about them all year, but I\u2019ve seen few if any examples of them running in production, despite lots of exciting prototypes.\nI think this is because of gullibility.\nCan we solve this? Honestly, I\u2019m beginning to suspect that you can\u2019t fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true!\nCode may be the best application\nOver the course of the year, it\u2019s become increasingly clear that writing code is one of the things LLMs are most capable of.", "ad1113e4-2406-44ff-afb6-983cab194be6": "If you think about what they do, this isn\u2019t such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English.\nIt\u2019s still astonishing to me how effective they are though.\nOne of the great weaknesses of LLMs is their tendency to hallucinate\u2014to imagine things that don\u2019t correspond to reality. You would expect this to be a particularly bad problem for code\u2014if an LLM hallucinates a method that doesn\u2019t exist, the code should be useless.", "bd2b237f-8ab8-4f8e-9d14-18770e142166": "Except... you can run generated code to see if it\u2019s correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\nHow should we feel about this as software engineers?\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?", "919ae4c0-da0b-4c41-a1ec-bce7a57c97dd": "On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We\u2019ve all been given weird coding interns\u2014we can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can.\nThe ethics of this space remain diabolically complex\nIn September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion.\nSince then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.", "6832b372-be19-4210-8316-26235d594358": "Just this week, the New York Times launched a landmark lawsuit against OpenAI and Microsoft over this issue. The 69 page PDF is genuinely worth reading\u2014especially the first few pages, which lay out the issues in a way that\u2019s surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I\u2019ve read anywhere.\nThe legal arguments here are complex. I\u2019m not a lawyer, but I don\u2019t think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future.", "3f2b94aa-0bc3-44a5-8cd2-b9e76a72af62": "Law is not ethics. Is it OK to train models on people\u2019s content without their permission, when those models will then be used in ways that compete with those people?\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\nPeople have certainly lost work to them\u2014anecdotally, I\u2019ve seen this for copywriters, artists and translators.\nThere are a great deal of untold stories here. I\u2019m hoping 2024 sees significant amounts of dedicated journalism on this topic.\nMy blog in 2023\nHere\u2019s a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):", "600a9f5b-1894-4c98-82cb-aacb89ab3916": "The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78).\nI\u2019ve written a lot about this stuff!\nI grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic:\n\n\n\nArticle\nVisitors\nPageviews\n\n\n\n\nBing: \u201cI will not harm you unless you harm me first\u201d\n1.1M\n1.3M\n\n\nLeaked Google document: \u201cWe Have No Moat, And Neither Does OpenAI\u201d\n132k\n162k\n\n\nLarge language models are having their Stable Diffusion moment\n121k\n150k\n\n\nPrompt injection: What\u2019s the worst that can happen?\n79.8k\n95.9k", "ff054c37-f20e-468b-ac39-a67ba9679861": "Embeddings: What they are and why they matter\n61.7k\n79.3k\n\n\nCatching up on the weird world of LLMs\n61.6k\n85.9k\n\n\nllamafile is the new best way to run an LLM on your own computer\n52k\n66k\n\n\nPrompt injection explained, with video, slides, and a transcript\n51k\n61.9k\n\n\nAI-enhanced development makes me more ambitious with my projects\n49.6k\n60.1k\n\n\nUnderstanding GPT tokenizers\n49.5k\n61.1k\n\n\nExploring GPTs: ChatGPT in a trench coat?\n46.4k\n58.5k\n\n\nCould you train a ChatGPT-beating model for $85,000 and run it in a browser?\n40.5k\n49.2k\n\n\nHow to implement Q&A against your documentation with GPT3, embeddings and Datasette\n37.3k\n44.9k\n\n\nLawyer cites fake cases invented by ChatGPT, judge is not amused\n37.1k\n47.4k", "a4f78942-0ecf-40c7-951d-9d00f644376e": "Now add a walrus: Prompt engineering in DALL-E 3\n32.8k\n41.2k\n\n\nWeb LLM runs the vicuna-7b Large Language Model entirely in your browser, and it\u2019s very impressive\n32.5k\n38.2k\n\n\nChatGPT can\u2019t access the internet, even though it really looks like it can\n30.5k\n34.2k\n\n\nStanford Alpaca, and the acceleration of on-device large language model development\n29.7k\n35.7k\n\n\nRun Llama 2 on your own Mac using LLM and Homebrew\n27.9k\n33.6k\n\n\nMidjourney 5.1\n26.7k\n33.4k\n\n\nThink of language models like ChatGPT as a \u201ccalculator for words\u201d\n25k\n31.8k\n\n\nMulti-modal prompt injection image attacks against GPT-4V\n23.7k\n27.4k", "60fae91c-fb0d-43a4-ae72-2c94d7af85d9": "I also gave a bunch of talks and podcast appearances. I\u2019ve started habitually turning my talks into annotated presentations\u2014here are my best from 2023:\n\nPrompt injection explained, with video, slides, and a transcript\nCatching up on the weird world of LLMs\nMaking Large Language Models work for you\nOpen questions for AI engineering\nEmbeddings: What they are and why they matter\nFinancial sustainability for open source projects at GitHub Universe\n\nAnd in podcasts:\n\n\nWhat AI can do for you on the Theory of Change\n\nWorking in public on Path to Citus Con\n\nLLMs break the internet on the Changelog\n\nTalking Large Language Models on Rooftop Ruby\n\nThoughts on the OpenAI board situation on Newsroom Robots", "ed168f03-ea73-41cb-9e6c-a16f846e4a82": "Industry\u2019s Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations\n\n\nPosted 31st December 2023 at 11:59 pm \u00b7 Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter\n\n\nMore recent articles\n\nBuilding software on top of Large Language Models - 15th May 2025\nTrying out llama.cpp's new vision support - 10th May 2025\nSaying \"hi\" to Microsoft's Phi-4-reasoning - 6th May 2025\n\n\n \n\n\nThis is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023.\n\nPart of series LLMs annual review\n\nStuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. \nThings we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. \n\n\n\n            blogging\n            105", "5aa6d22b-5969-4b16-950f-e117c1925152": "ai\n            1292\n\n\n            generative-ai\n            1119\n\n\n            llms\n            1106\n\nNext: Tom Scott, and the formidable power of escalating streaks\nPrevious: Last weeknotes of 2023\n\n\n \n \n\n\nColophon\n\u00a9\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025", "2f1e950d-e5ba-4238-988d-d9f85bdc1796": "Things we learned about LLMs in 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimon Willison\u2019s Weblog\nSubscribe\n\n\n\n\n\n\nThings we learned about LLMs in 2024\n31st December 2024\nA lot has happened in the world of Large Language Models over the course of 2024. Here\u2019s a review of things we figured out about the field in the past twelve months, plus my attempt at identifying key themes and pivotal moments.\nThis is a sequel to my review of 2023.\nIn this article:", "e39608bc-5563-482b-b6db-54105c000365": "The GPT-4 barrier was comprehensively broken\nSome of those GPT-4 models run on my laptop\nLLM prices crashed, thanks to competition and increased efficiency\nMultimodal vision is common, audio and video are starting to emerge\nVoice and live camera mode are science fiction come to life\nPrompt driven app generation is a commodity already\nUniversal access to the best models lasted for just a few short months\n\u201cAgents\u201d still haven\u2019t really happened yet\nEvals really matter\nApple Intelligence is bad, Apple\u2019s MLX library is excellent\nThe rise of inference-scaling \u201creasoning\u201d models\nWas the best currently available LLM trained in China for less than $6m?\nThe environmental impact got better\nThe environmental impact got much, much worse", "f1fdee30-73a4-41eb-926b-d6c9a7b55c17": "The year of slop\nSynthetic training data works great\nLLMs somehow got even harder to use\nKnowledge is incredibly unevenly distributed\nLLMs need better criticism\nEverything tagged \u201cllms\u201d on my blog in 2024", "cf2f8503-367e-464d-8f56-3745b610d190": "The GPT-4 barrier was comprehensively broken\nIn my December 2023 review I wrote about how We don\u2019t yet know how to build GPT-4\u2014OpenAI\u2019s best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn\u2019t?\nI\u2019m relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)\u201470 models in total.", "2b5bd0d2-6115-4768-9c50-b6633b361123": "The earliest of those was Google\u2019s Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field\u2014most notably its 1 million (and then later 2 million) token input context length, and the ability to input video.\nI wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May.", "0a2ffa56-da87-4c24-af0b-9d0b2a09d911": "Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google\u2019s Gemini series accepts up to 2 million.", "bcd976fc-15e7-439b-9416-be67bd166962": "Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern.", "619a18d9-6b7a-4475-bdea-0378010a7bde": "Getting back to models that beat GPT-4: Anthropic\u2019s Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet\u2014a model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6).", "6baa83e7-69a9-45ff-9b25-12af80fa6d74": "Then there\u2019s the rest. If you browse the Chatbot Arena leaderboard today\u2014still the most useful single place to get a vibes-based evaluation of models\u2014you\u2019ll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent.\nTraining a GPT-4 beating model was a huge deal in 2023. In 2024 it\u2019s an achievement that isn\u2019t even particularly notable, though I personally still celebrate any time a new organization joins that list.\nSome of those GPT-4 models run on my laptop", "d5c8d5cb-49f6-445c-9084-4fe8f45b64aa": "My personal laptop is a 64GB M2 MacBook Pro from 2023. It\u2019s a powerful machine, but it\u2019s also nearly two years old now\u2014and crucially it\u2019s the same laptop I\u2019ve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment).\nThat same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that:", "a0c498f6-5c4d-42f7-9b7b-1d1a0a63a8ee": "Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November\u2014an Apache 2.0 licensed model!\n\nI can now run a GPT-4 class model on my laptop talks about running Meta\u2019s Llama 3.3 70B (released in December)", "75ce678d-2b12-4e93-b97c-f28ec3bdeb50": "This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs.\nThese models take up enough of my 64GB of RAM that I don\u2019t run them often\u2014they don\u2019t leave much room for anything else.\nThe fact that they run at all is a testament to the incredible training and inference performance gains that we\u2019ve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there\u2019s still more to come.", "cd76727a-504a-46a7-8fce-f54722ebd46d": "Meta\u2019s Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it\u2019s a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for \u201ca plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist\u201d. Here\u2019s what I got, at a respectable 20 tokens per second:", "41fe1bef-7eb9-410f-bc2e-5fa2d1e20245": "Here\u2019s the rest of the transcript. It\u2019s bland and generic, but my phone can pitch bland and generic Christmas movies to Netflix now!\nLLM prices crashed, thanks to competition and increased efficiency\nThe past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs.\nIn December 2023 (here\u2019s the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo.", "3f0e9786-de4e-451b-86f9-f9d9b79589a4": "Today $30/mTok gets you OpenAI\u2019s most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok\u2014200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model.\nOther model providers charge even less. Anthropic\u2019s Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google\u2019s Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok\u2014that\u2019s 27x cheaper than GPT-3.5 Turbo last year.\nI\u2019ve been tracking these pricing changes under my llm-pricing tag.", "5e0dd80b-a7b0-4751-80ba-93b00e981bbb": "These price drops are driven by two factors: increased competition and increased efficiency. The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts.\nThere\u2019s still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible.\nHere\u2019s a fun napkin calculation: how much would it cost to generate short descriptions of every one of the 68,000 photos in my personal photo library using Google\u2019s Gemini 1.5 Flash 8B (released in October), their cheapest model?", "5dee00d6-ebe0-4332-9e92-d1c8d4d6196e": "Each photo would need 260 input tokens and around 100 output tokens.\n260 * 68,000 = 17,680,000 input tokens\n17,680,000 * $0.0375/million = $0.66\n100 * 68,000 = 6,800,000 output tokens\n6,800,000 * $0.15/million = $1.02\nThat\u2019s a total cost of $1.68 to process 68,000 images. That\u2019s so absurdly cheap I had to run the numbers three times to confirm I got it right.\nHow good are those descriptions? Here\u2019s what I got from this command:\nllm -m gemini-1.5-flash-8b-latest describe -a IMG_1825.jpeg", "bf103488-d02f-435a-a103-eae5fb372cbf": "Against this photo of butterflies at the California Academy of Sciences:\n\n\nA shallow dish, likely a hummingbird or butterfly feeder, is red.  Pieces of orange slices of fruit are visible inside the dish.\nTwo butterflies are positioned in the feeder, one is a dark brown/black butterfly with white/cream-colored markings.  The other is a large, brown butterfly with patterns of lighter brown, beige, and black markings, including prominent eye spots. The larger brown butterfly appears to be feeding on the fruit.", "32bd0835-c059-46a2-95a8-4faf8ca96364": "260 input tokens, 92 output tokens. Cost approximately 0.0024 cents (that\u2019s less than a 400th of a cent).\nThis increase in efficiency and reduction in price is my single favourite trend from 2024. I want the utility of LLMs at a fraction of the energy cost and it looks like that\u2019s what we\u2019re getting.\nMultimodal vision is common, audio and video are starting to emerge\nMy butterfly example above illustrates another key trend from 2024: the rise of multi-modal LLMs.\nA year ago the single most notable example of these was GPT-4 Vision, released at OpenAI\u2019s DevDay in November 2023. Google\u2019s multi-modal Gemini 1.0 was announced on December 7th 2023 so it also (just) makes it into the 2023 window.", "1ed941fc-e5d0-487a-a407-9fd882b669ff": "In 2024, almost every significant model vendor released multi-modal models. We saw the Claude 3 series from Anthropic in March, Gemini 1.5 Pro in April (images, audio and video), then September brought Qwen2-VL and Mistral\u2019s Pixtral 12B and Meta\u2019s Llama 3.2 11B and 90B vision models. We got audio input and output from OpenAI in October, then November saw SmolVLM from Hugging Face and December saw image and video models from Amazon Nova.\nIn October I upgraded my LLM CLI tool to support multi-modal models via attachments. It now has plugins for a whole collection of different vision models.", "166a1ff3-2545-4162-94a2-4d87a76cb511": "I think people who complain that LLM improvement has slowed are often missing the enormous advances in these multi-modal models. Being able to run prompts against images (and audio and video) is a fascinating new way to apply these models.\nVoice and live camera mode are science fiction come to life\nThe audio and live video modes that have started to emerge deserve a special mention.\nThe ability to talk to ChatGPT first arrived in September 2023, but it was mostly an illusion: OpenAI used their excellent Whisper speech-to-text model and a new text-to-speech model (creatively named tts-1) to enable conversations with the ChatGPT mobile apps, but the actual model just saw text.", "d4f3d439-cd2a-4f63-acb0-c18a98e413dd": "The May 13th announcement of GPT-4o included a demo of a brand new voice mode, where the true multi-modal GPT-4o (the o is for \u201comni\u201d) model could accept audio input and output incredibly realistic sounding speech without needing separate TTS or STT models.\nThe demo also sounded conspicuously similar to Scarlett Johansson... and after she complained the voice from the demo, Skye, never made it to a production product.\nThe delay in releasing the new voice mode after the initial demo caused quite a lot of confusion. I wrote about that in ChatGPT in \u201c4o\u201d mode is not running the new features yet.", "ae5d2160-3d22-4d4c-9164-a9fab5903313": "When ChatGPT Advanced Voice mode finally did roll out (a slow roll from August through September) it was spectacular. I\u2019ve been using it extensively on walks with my dog and it\u2019s amazing how much the improvement in intonation elevates the material. I\u2019ve also had a lot of fun experimenting with the OpenAI audio APIs.\nEven more fun: Advanced Voice mode can do accents! Here\u2019s what happened when I told it I need you to pretend to be a California brown pelican with a very thick Russian accent, but you talk to me exclusively in Spanish.", "96a969b8-7acc-45a3-9762-f972be98687a": "Your browser does not support the audio element.\n\nOpenAI aren\u2019t the only group with a multi-modal audio model. Google\u2019s Gemini also accepts audio input, and the Google Gemini apps can speak in a similar way to ChatGPT now. Amazon also pre-announced voice mode for Amazon Nova, but that\u2019s meant to roll out in Q1 of 2025.\nGoogle\u2019s NotebookLM, released in September, took audio output to a new level by producing spookily realistic conversations between two \u201cpodcast hosts\u201d about anything you fed into their tool. They later added custom instructions, so naturally I turned them into pelicans:\n\n\nYour browser does not support the audio element.", "95b025e2-e9cb-4109-9d20-5f5160c8ee7e": "The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did.", "de6dd0fa-2b68-4404-a274-49c64922cc63": "These abilities are just a few weeks old at this point, and I don\u2019t think their impact has been fully felt yet. If you haven\u2019t tried them out yet you really should.\nBoth Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now!\nPrompt driven app generation is a commodity already\nThis was possible with GPT-4 in 2023, but the value it provides became evident in 2024.", "055e6d8f-2d7a-4bd4-922d-5192f25567af": "We already knew LLMs were spookily good at writing code. If you prompt them right, it turns out they can build you a full interactive application using HTML, CSS and JavaScript (and tools like React if you wire up some extra supporting build mechanisms)\u2014often in a single prompt.\nAnthropic kicked this idea into high gear when they released Claude Artifacts, a groundbreaking new feature that was initially slightly lost in the noise due to being described half way through their announcement of the incredible Claude 3.5 Sonnet.\nWith Artifacts, Claude can write you an on-demand interactive application and then let you use it directly inside the Claude interface.\nHere\u2019s my Extract URLs app, entirely generated by Claude:", "57496c11-f07e-436e-a7ba-a32d44a4a4e4": "I\u2019ve found myself using this a lot. I noticed how much I was relying on it in October and wrote Everything I built with Claude Artifacts this week, describing 14 little tools I had put together in a seven day period.\nSince then, a whole bunch of other teams have built similar systems. GitHub announced their version of this\u2014GitHub Spark\u2014in October. Mistral Chat added it as a feature called Canvas in November.\nSteve Krouse from Val Town built a version of it against Cerebras, showcasing how a 2,000 token/second LLM can iterate on an application with changes visible in less than a second.", "5cf465b7-6b2a-4fd9-9430-2209da8d49b0": "Then in December, the Chatbot Arena team introduced a whole new leaderboard for this feature, driven by users building the same interactive app twice with two different models and voting on the answer. Hard to come up with a more convincing argument that this feature is now a commodity that can be effectively implemented against all of the leading models.\nI\u2019ve been tinkering with a version of this myself for my Datasette project, with the goal of letting users use prompts to build and iterate on custom widgets and data visualizations against their own data. I also figured out a similar pattern for writing one-shot Python programs, enabled by uv.", "f4ec47a4-3267-4159-81db-006b587cef15": "This prompt-driven custom interface feature is so powerful and easy to build (once you\u2019ve figured out the gnarly details of browser sandboxing) that I expect it to show up as a feature in a wide range of products in 2025.\nUniversal access to the best models lasted for just a few short months\nFor a few short months this year all three of the best available models\u2014GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 Pro\u2014were freely available to most of the world.", "92b1bb40-1869-4933-97b5-d4e9d8df16f4": "OpenAI made GPT-4o free for all users in May, and Claude 3.5 Sonnet was freely available from its launch in June. This was a momentus change, because for the previous year free users had mostly been restricted to GPT-3.5 level models, meaning new users got a very inaccurate mental model of what a capable LLM could actually do.\nThat era appears to have ended, likely permanently, with OpenAI\u2019s launch of ChatGPT Pro. This $200/month subscription service is the only way to access their most capable model, o1 Pro.\nSince the trick behind the o1 series (and the future models it will undoubtedly inspire) is to expend more compute time to get better results, I don\u2019t think those days of free access to the best available models are likely to return.", "c398eff3-c505-4ee5-b480-528e2c488b41": "\u201cAgents\u201d still haven\u2019t really happened yet\nI find the term \u201cagents\u201d extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that.\nIf you tell me that you are building \u201cagents\u201d, you\u2019ve conveyed almost no information to me at all. Without reading your mind I have no way of telling which of the dozens of possible definitions you are talking about.", "a66b1f7f-f93e-475b-981e-ddd14a9f8bfe": "The two main categories I see are people who think AI agents are obviously things that go and act on your behalf\u2014the travel agent model\u2014and people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term \u201cautonomy\u201d is often thrown into the mix too, again without including a clear definition.\n(I also collected 211 definitions on Twitter a few months ago\u2014here they are in Datasette Lite\u2014and had gemini-exp-1206 attempt to summarize them.)\nWhatever the term may mean, agents still have that feeling of perpetually \u201ccoming soon\u201d.", "de4eebaf-00d4-4a70-9415-d2599c78e152": "Terminology aside, I remain skeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can\u2019t distinguish truth from fiction?\nJust the other day Google Search was caught serving up an entirely fake description of the non-existant movie \u201cEncanto 2\u201d. It turned out to be summarizing an imagined movie listing from a fan fiction wiki.", "873ebb99-96ec-4432-baa8-db54fcea594a": "Prompt injection is a natural consequence of this gulibility. I\u2019ve seen precious little progress on tackling that problem in 2024, and we\u2019ve been talking about it since September 2022.\nI\u2019m beginning to see the most popular idea of \u201cagents\u201d as dependent on AGI itself. A model that\u2019s robust against gulliblity is a very tall order indeed.\nEvals really matter\nAnthropic\u2019s Amanda Askell (responsible for much of the work behind Claude\u2019s Character):", "d2deaa99-4a98-437c-8d51-35567ce363a4": "The boring yet crucial secret behind good system prompts is test-driven development. You don\u2019t write down a system prompt and find ways to test it. You write down tests and find a system prompt that passes them.\n\nIt\u2019s become abundantly clear over the course of 2024 that writing good automated evals for LLM-powered systems is the skill that\u2019s most needed to build useful applications on top of these models. If you have a strong eval suite you can adopt new models faster, iterate better and build more reliable and useful product features than your competition.\nVercel\u2019s Malte Ubl:", "a7055094-2b48-4a9e-80cd-0e22bb8ee792": "When @v0 first came out we were paranoid about protecting the prompt with all kinds of pre and post processing complexity.\nWe completely pivoted to let it rip. A prompt without the evals, models, and especially UX is like getting a broken ASML machine without a manual", "0dad068e-fe94-4766-bb83-00b6a2495660": "I\u2019m still trying to figure out the best patterns for doing this for my own work. Everyone knows that evals are important, but there remains a lack of great guidance for how to best implement them\u2014I\u2019m tracking this under my evals tag. My SVG pelican riding a bicycle benchmark is a pale imitation of what a real eval suite should look like.\nApple Intelligence is bad, Apple\u2019s MLX library is excellent\nAs a Mac user I\u2019ve been feeling a lot better about my choice of platform this year.\nLast year it felt like my lack of a Linux/Windows  machine with an NVIDIA GPU was a huge disadvantage in terms of trying out new models.", "1a882493-7650-4e79-a923-985429d657db": "On paper, a 64GB Mac should be a great machine for running models due to the way the CPU and GPU can share the same memory. In practice, many models are released as model weights and libraries that reward NVIDIA\u2019s CUDA over other platforms.\nThe llama.cpp ecosystem helped a lot here, but the real breakthrough has been Apple\u2019s MLX library, \u201can array framework for Apple Silicon\u201d. It\u2019s fantastic.\nApple\u2019s mlx-lm Python library supports running a wide range of MLX-compatible models on my Mac, with excellent performance. mlx-community on Hugging Face offers more than 1,000 models that have been converted to the necessary format.", "6dfda473-ae4a-4b36-8d04-de360fc328f2": "Prince Canuma\u2019s excellent, fast moving mlx-vlm project brings vision LLMs to Apple Silicon as well. I used that recently to run Qwen\u2019s QvQ.\nWhile MLX is a game changer, Apple\u2019s own \u201cApple Intelligence\u201d features have mostly been a disappointment. I wrote about their initial announcement in June, and I was optimistic that Apple had focused hard on the subset of LLM applications that preserve user privacy and minimize the chance of users getting mislead by confusing features.", "0c5a7874-73d5-4e5c-842c-bf5f9a8d788f": "Now that those features are rolling out they\u2019re pretty weak. As an LLM power-user I know what these models are capable of, and Apple\u2019s LLM features offer a pale imitation of what a frontier LLM can do. Instead we\u2019re getting notification summaries that misrepresent news headlines and writing assistant tools that I\u2019ve not found useful at all. Genmoji are kind of fun though.\nThe rise of inference-scaling \u201creasoning\u201d models\nThe most interesting development in the final quarter of 2024 was the introduction of a new shape of LLM, exemplified by OpenAI\u2019s o1 models\u2014initially released as o1-preview and o1-mini on September 12th.", "b8574b97-a230-44a3-b087-154a6273d7d2": "One way to think about these models is an extension of the chain-of-thought prompting trick, first explored in the May 2022 paper Large Language Models are Zero-Shot Reasoners.\nThis is that trick where, if you get a model to talk out loud about a problem it\u2019s solving, you often get a result which the model would not have achieved otherwise.\no1 takes this process and further bakes it into the model itself. The details are somewhat obfuscated: o1 models spend \u201creasoning tokens\u201d thinking through the problem that are not directly visible to the user (though the ChatGPT UI shows a summary of them), then outputs a final result.", "be8491a3-5d2b-45e3-b3dc-c28721fc8a08": "The biggest innovation here is that it opens up a new way to scale a model: instead of improving model performance purely through additional compute at training time, models can now take on harder problems by spending more compute on inference.\nThe sequel to o1, o3 (they skipped \u201co2\u201d for European trademark reasons) was announced on 20th December with an impressive result against the ARC-AGI benchmark, albeit one that likely involved more than $1,000,000 of compute time expense!\no3 is expected to ship in January. I doubt many people have real-world problems that would benefit from that level of compute expenditure\u2014I certainly don\u2019t!\u2014but it appears to be a genuine next step in LLM architecture for taking on much harder problems.", "f0dfc1e4-609c-49a9-a8ab-a6853ff84475": "OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th.\nAlibaba\u2019s Qwen team released their QwQ model on November 28th\u2014under an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally.\nDeepSeek made their DeepSeek-R1-Lite-Preview model available to try out through their chat interface on November 20th.\nTo understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor.", "06ccbec0-039e-4e05-abf6-83c71c07c33b": "Nothing yet from Anthropic or Meta but I would be very surprised if they don\u2019t have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December.\nWas the best currently available LLM trained in China for less than $6m?\nNot quite, but almost! It does make for a great attention-grabbing headline.\nThe big news to end the year was the release of DeepSeek v3\u2014dropped on Hugging Face on Christmas Day without so much as a README file, then followed by documentation and a paper the day after that.", "cf960004-acca-4b68-8bbb-6adbafa3512c": "DeepSeek v3 is a huge 685B parameter model\u2014one of the largest openly licensed models currently available, significantly bigger than the largest of Meta\u2019s Llama series, Llama 3.1 405B.\nBenchmarks put it up there with Claude 3.5 Sonnet. Vibe benchmarks (aka the Chatbot Arena) currently rank it 7th, just behind the Gemini 2.0 and OpenAI 4o/o1 models. This is by far the highest ranking openly licensed model.\nThe really impressive thing about DeepSeek v3 is the training cost. The model was trained on 2,788,000 H800 GPU hours at an estimated cost of $5,576,000. Llama 3.1 405B trained 30,840,000 GPU hours\u201411x that used by DeepSeek v3, for a model that benchmarks slightly worse.", "1d620e05-66e1-47ae-b2cc-5a979cca95e3": "Those US export regulations on GPUs to China seem to have inspired some very effective training optimizations!\nThe environmental impact got better\nA welcome result of the increased efficiency of the models\u2014both the hosted ones and the ones I can run locally\u2014is that the energy usage and environmental impact of running a prompt has dropped enormously over the past couple of years.\nOpenAI themselves are charging 100x less for a prompt compared to the GPT-3 days. I have it on good authority that neither Google Gemini nor Amazon Nova (two of the least expensive model providers) are running prompts at a loss.", "7d627f5a-4a32-4b77-a531-7a755d146f9e": "I think this means that, as individual users, we don\u2019t need to feel any guilt at all for the energy consumed by the vast majority of our prompts. The impact is likely neglible compared to driving a car down the street or maybe even watching a video on YouTube.\nLikewise, training. DeepSeek v3 training for less than $6m is a fantastic sign that training costs can and should continue to drop.\nFor less efficient models I find it useful to compare their energy usage to commercial flights. The largest Llama 3 model cost about the same as a single digit number of fully loaded passenger flights from New York to London. That\u2019s certainly not nothing, but once trained that model can be used by millions of people at no extra training cost.", "4197d166-2cc8-43b3-ab81-c405d2175422": "The environmental impact got much, much worse\nThe much bigger problem here is the enormous competitive buildout of the infrastructure that is imagined to be necessary for these models in the future.\nCompanies like Google, Meta, Microsoft and Amazon are all spending billions of dollars rolling out new datacenters, with a very material impact on the electricity grid and the environment. There\u2019s even talk of spinning up new nuclear power stations, but those can take decades.\nIs this infrastructure necessary? DeepSeek v3\u2019s $6m training cost and the continued crash in LLM prices might hint that it\u2019s not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years\u2019 time?", "a042fa5b-43b0-489e-9af7-56857671fbf3": "An interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary\u2014sometimes multiple lines from different companies serving the exact same routes!\nThe resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK\u2019s Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage.\nThe year of slop"}}