{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… pandas version: 2.2.3\n",
            "âœ… ragas version: 0.2.15\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(\"âœ… pandas version:\", pd.__version__)\n",
        "\n",
        "import ragas\n",
        "from ragas.testset     import TestsetGenerator\n",
        "from ragas.llms        import LangchainLLMWrapper\n",
        "from ragas.embeddings  import LangchainEmbeddingsWrapper\n",
        "from langchain_openai  import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "\n",
        "print(\"âœ… ragas version:\", ragas.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-cohere rank_bm25 pandas ragas langsmith rapidfuzz qdrant-client \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-18 16:32:48--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-18 16:32:48 (37.5 MB/s) - â€˜john_wick_1.csvâ€™ saved [19628/19628]\n",
            "\n",
            "--2025-05-18 16:32:49--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-18 16:32:49 (14.8 MB/s) - â€˜john_wick_2.csvâ€™ saved [14747/14747]\n",
            "\n",
            "--2025-05-18 16:32:50--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-18 16:32:50 (13.9 MB/s) - â€˜john_wick_3.csvâ€™ saved [13888/13888]\n",
            "\n",
            "--2025-05-18 16:32:51--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-18 16:32:51 (19.4 MB/s) - â€˜john_wick_4.csvâ€™ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [],
      "source": [
        "documents[0]\n",
        "\n",
        "import pickle\n",
        "with open(\"documents.pkl\", \"wb\") as f:\n",
        "    pickle.dump(documents, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, people generally liked the first John Wick movie. The reviews highlight Keanu Reeves' cool and confident performance, the stylish and well-choreographed action sequences, and the film's brisk pace and entertaining plot. Many reviewers praised it as one of the best action movies in recent years, recommending it especially to action fans. Although there are some differing opinions, with a few reviewers finding it generic or giving moderate ratings, the overall sentiment is positive and the film is considered a standout in the genre.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n- /review/rw4854296/?ref_=tt_urv\\n\\nThis review is titled \"A Masterpiece & Brilliant Sequel\" for John Wick 3.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie *John Wick* (2014), John Wick, played by Keanu Reeves, is a retired hitman who is grieving the recent death of his wife. His wife had left him a puppy to help him cope with her death. However, his quiet life is shattered when a group of gangsters led by a young Russian-American thug break into his home, kill his dog, and steal his cherished car. This brutal act pulls John out of retirement and sets him on a violent path of revenge against the criminals responsible. \\n\\nJohn Wick unleashes a relentless and highly skilled assault on the gangsters, demonstrating his lethal assassin skills. The thugs\\' actions awaken the legend of John Wick â€” a feared and highly skilled hitman known as \"The Boogeyman.\" As a result, John finds himself targeted by many killers and bounty hunters who want to take him down, leading to intense and expertly choreographed action sequences filled with shootouts and hand-to-hand combat.\\n\\nThe film is known for its stylish, kinetic action, suspense, and a simple but powerful revenge-driven plot: John Wick seeks vengeance for the loss of his dog and everything his wife left behind, waging a one-man war against the Russian mafia.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Overall, opinions about the John Wick films appear mixed based on the provided reviews:\\n\\n- The first John Wick movie was generally very well-liked. Reviews describe it as \"something special,\" with smooth, stylish action sequences and an engaging world, receiving high ratings like 8 and 10 out of 10. It is praised as a must-see for action fans.\\n\\n- The fourth film, John Wick: Chapter 4, received a more critical review, calling it the weakest in the series with little plot and mostly gunfights, although it still received a rating of 4 out of 10 in the given example.\\n\\n- The third film, John Wick 3, received very negative feedback from the one provided review, describing it as mindless, overly violent, and plotless, with a rating of 1 out of 10.\\n\\nIn summary, people generally liked the original John Wick film quite a lot, but later installments have received more mixed to negative reactions from some reviewers.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'No, none of the reviews provided have a rating of 10. Therefore, there are no URLs to reviews with a rating of 10.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The movie *John Wick* (the first film) centers around an emotionally driven action story featuring Keanu Reeves as John Wick. It is about a retired hitman who embarks on a relentless and beautifully choreographed quest for vengeance after tragic events disrupt his peaceful life. The film is praised for its intense hand-to-hand combat, gunfights, and surprisingly emotional depth for an action movie. Overall, it is highly regarded as an exciting and well-executed action thriller that keeps viewers engaged throughout.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, people generally liked the first John Wick film. Reviews describe it as the best action film of the year and one of the best in the past decade, praising Keanu Reeves' performance, the slick and intense action sequences, and the unique criminal underworld setting. It is highly recommended for action fans and considered fun, stylish, and well-executed. However, the third film in the series received a more mixed review, suggesting the magic may have diminished over time.\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n- /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the first John Wick movie, John Wick, a retired hitman, seeks revenge after a group of gangsters steal his car and kill his beloved dog, which was a final gift from his deceased wife. This brutal act drags him out of retirement and into a violent rampage against those responsible, showcasing intense action, fights, and shootouts.\\n\\nIn John Wick 2, after resolving issues with the Russian mafia, John returns home but is soon visited by the mobster Santino D'Antonio, who forces him to honor a blood oath (marker) by helping him. John initially refuses, leading Santino to blow up his house. John is compelled to kill Santino's sister, Gianna D'Antonio, in Rome so that Santino can take a seat on the High Table of the criminal organizations. After completing the task, Santino betrays John by putting a $7 million contract on his head, forcing John to fight against numerous professional killers while vowing to kill Santino, who is no longer protected by his marker.\\n\\nOverall, John Wick is a story about a legendary hitman pulled back into a deadly underworld by personal loss, loyalty, and betrayal, leading to relentless action and a quest for vengeance.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=bm25_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, people generally like John Wick. The franchise has been praised for its expertly choreographed and well-executed action sequences, with many reviewers highlighting Keanu Reeves' performance and the consistent quality of the films. For example, John Wick 4 received high ratings and was described as possibly one of the best action movies ever, and the earlier films were also well-received and considered standards for action movies in Hollywood. However, there are some mixed opinions, especially about John Wick 4, where a few reviews mention a lack of storyline or criticize it for being over the top. But overall, the general reception is positive.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n/review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The movie \"John Wick\" centers around a former hitman named John Wick, played by Keanu Reeves, who seeks revenge after a brutal home invasion in which thugs kill his beloved dogâ€”one of the last gifts from his deceased wife. This event pulls him back into a violent criminal underworld. The film is known for its beautifully choreographed action sequences, combining hand-to-hand combat and gunfights with a stylish presentation. It features intense and brutal fights, and John Wick is portrayed as a ruthless character navigating a world filled with equally dangerous individuals. The story is relatively simple, focusing on revenge and the consequences of violence, but it is executed with great intensity and emotional weight.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/_2/jfrqr6ps3b1bp6phc70rhdrc0000gp/T/ipykernel_72688/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, people generally liked the John Wick series. One review praised the first John Wick movie for its well-choreographed action and emotional setup, recommending it highly. Another review expressed that the series has been remarkably consistent and well received, even stating that \"John Wick: Chapter 4\" might be the best the series has to offer. However, there are also some negative opinions, such as one reviewer finding \"John Wick 4\" horrible and criticizing its plot and fight scenes.\\n\\nIn summary, while there are mixed opinions, the overall reception of the John Wick series appears to be generally positive.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is at least one review with a rating of 10. \\n\\nHere is the URL to that review:  \\n/review/rw4854296/?ref_=tt_urv\\n\\nThis review is for \"John Wick 3\" and the rating given is 10.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the first John Wick movie, John Wick is a retired assassin who re-enters the dangerous world after gangsters kill his dog, a final gift from his deceased wife, and steal his car. Seeking revenge, he unleashes a violent and relentless vendetta against those responsible, facing numerous hitmen who come after him because of the high bounty on his head.\\n\\nThe story centers on John's deep thirst for retribution and showcases intense action, including shootouts and fights, as he battles his enemies.\\n\\nIn summary, John Wick is about a legendary ex-hitman who is pulled back into a deadly and action-packed fight for vengeance after losing his dog and car to criminals.\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked the original John Wick film. The reviews for John Wick 1 are overwhelmingly positive, praising its stylish and well-choreographed action sequences, Keanu Reeves\\' performance, and the unique criminal underworld it presents. Reviewers describe it as a fun, violent, and kinetic action movie with a straightforward but effective plot centered on revenge. For example, one reviewer gave it a perfect 10 rating calling it a \"must see for action fans\" and highlighting its smooth action and cool noir world. Another gave it a 9, calling it \"the coolest action film you\\'ll see all year\" and praising its brisk pacing and intense action scenes. Even generally enthusiastic reviews emphasize its successful simplicity and the emotionally engaging setup involving John Wick\\'s dog.\\n\\nWhile there are some more neutral opinionsâ€”such as one reviewer rating it 6 out of 10 who felt it was a \"generic action thriller\"â€”the overall tone from multiple highly rated reviews shows that John Wick 1 was well liked and appreciated for revitalizing the action genre.\\n\\nIn contrast, the later sequels received a more mixed response, with some reviewers criticizing the increasingly over-the-top and implausible aspects of the series, especially John Wick 3 and John Wick 4. But for the original film, the reception was mostly very positive.\\n\\n**Summary:** Yes, people generally liked John Wick (the first film) â€” it was praised for its action, style, and Keanu Reeves\\' performance, receiving mostly high ratings and positive reviews.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is at least one review with a rating of 10. Here is the URL to that review:\\n\\n- Review Title: \"A Masterpiece & Brilliant Sequel\"  \\n  Rating: 10  \\n  URL: /review/rw4854296/?ref_=tt_urv\\n\\nIf you need more information or additional reviews, please let me know!'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the original \"John Wick\" movie (2014), the story centers around John Wick, a retired hitman who is mourning the death of his wife. After her death, John tries to rebuild his life. However, his peaceful life is shattered when a group of gangsters, led by a young Russian-American punk, break into his house, beat him, kill his beloved dog (a final gift from his late wife), and steal his classic car. This attack triggers John to come out of retirement and seek revenge.\\n\\nJohn Wick unleashes a relentless and violently brutal vendetta against the Russian mobsters responsible, showcasing his lethal skills and deadly efficiency. The gangsters soon realize they have awakened a legendary assassin known as \"The Boogeyman,\" and a large bounty is placed on John\\'s head, causing hitmen from all over to pursue him.\\n\\nThroughout the film, John fights through numerous assassins and criminals in highly choreographed action sequences, blending gunfights, martial arts, and suspenseful shootouts. The movie highlights a dark, stylized criminal underworld where respect and connections matter, and John\\'s return to violence disrupts the established order.\\n\\nIn essence, \"John Wick\" is a kinetic, emotionally charged revenge thriller where a grieving man turns back into an unstoppable assassin to avenge the loss of his dog and reclaim what was taken from him. The film is praised for its stylish action, intense choreography, and Keanu Reeves\\' compelling performance.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rpcio (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick, especially the first film. Reviews highlight it as a special and stylish action movie with smooth, well-choreographed action sequences, an interesting world, and a compelling performance by Keanu Reeves. It is described as slick, violent fun, highly entertaining, and refreshing in the action genre. The franchise overall has remained consistent and well received, with strong ratings for multiple installments.\\n\\nThere are some mixed opinions on later films, such as John Wick 3, where one reviewer felt \"the magic is gone\" and gave it a lower rating, but others still praised the action and intensity.\\n\\nIn summary, John Wick is generally liked, particularly for its action and style, and the series is regarded as maintaining high quality across its sequels.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is:\\n\\n/review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In \"John Wick,\" Keanu Reeves plays John Wick, a retired hitman who is forced back into a violent world to seek revenge. The story begins when a group of gangsters, led by the son of a Russian mob boss whom John used to work for, break into his house, beat him up, kill his puppy (a final gift from his deceased wife), and steal his beloved car. This act of cruelty unknowingly awakens John Wickâ€™s lethal skills and legacy. Driven by grief and rage, John embarks on a relentless and ultra-violent vendetta against the gangsters. Throughout the film, he faces numerous assassins sent after him by the Russian mob boss who wants to protect his son. The movie is known for its stylish, well-choreographed action sequences, kinetic chaos, and a simple but emotionally compelling revenge-driven plot.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/bin/python: No module named pip\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ…  Reloaded test-set from disk with 12 Q-A pairs\n",
            "ðŸ  Environment ready â€“ go ahead and run the Activity-2 evaluation cell.\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  QUICK-FIX BOOTSTRAP  â–¸ installs deps, resurrects `dataset` & docs   â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 1ï¸âƒ£  Install any missing wheels *inside* the running kernel\n",
        "%pip install --quiet --upgrade rapidfuzz ragas langsmith pandas\n",
        "\n",
        "# 2ï¸âƒ£  Re-import everything we need\n",
        "import os, pickle, json, sys, pathlib\n",
        "import pandas as pd\n",
        "from langsmith import Client                         # pip name: langsmith :contentReference[oaicite:0]{index=0}\n",
        "from ragas.testset import TestsetGenerator           # pip name: ragas :contentReference[oaicite:1]{index=1}\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# 3ï¸âƒ£  Restore previously-saved objects if they exist â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if pathlib.Path(\"dataset.pkl\").exists():\n",
        "    with open(\"dataset.pkl\", \"rb\") as f:\n",
        "        dataset = pickle.load(f)\n",
        "    print(f\"âœ…  Reloaded test-set from disk with {len(dataset)} Q-A pairs\")\n",
        "else:\n",
        "    # 3a.  Re-hydrate the source *documents* quickly (only light I/O)\n",
        "    if pathlib.Path(\"documents.pkl\").exists():\n",
        "        with open(\"documents.pkl\", \"rb\") as f:\n",
        "            documents = pickle.load(f)\n",
        "        print(f\"âœ…  Reloaded {len(documents)} documents from disk\")\n",
        "    else:\n",
        "        # Fallback â€“ load the four John-Wick CSVs (much faster than rerunning full pipeline)\n",
        "        docs = []\n",
        "        for csv in (\"john_wick_1.csv\",\"john_wick_2.csv\",\"john_wick_3.csv\",\"john_wick_4.csv\"):\n",
        "            df = pd.read_csv(csv)\n",
        "            docs.extend([Document(page_content=row[\"content\"]) for _, row in df.iterrows()])\n",
        "        documents = docs\n",
        "        with open(\"documents.pkl\", \"wb\") as f:\n",
        "            pickle.dump(documents, f)\n",
        "        print(f\"âœ…  Parsed & cached {len(documents)} docs from CSVs\")\n",
        "\n",
        "    # 3b.  QUICK synthetic test-set (cheap: only 10 Q-A pairs)\n",
        "    llm        = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "    embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "    generator  = TestsetGenerator(llm=llm, embedding_model=embeddings)\n",
        "    dataset    = generator.generate_with_langchain_docs(documents, testset_size=10)\n",
        "    with open(\"dataset.pkl\", \"wb\") as f:\n",
        "        pickle.dump(dataset, f)\n",
        "    print(f\"âœ…  Generated and cached new test-set with {len(dataset)} Q-A pairs\")\n",
        "\n",
        "# 4ï¸âƒ£  Make *dataset* visible to later cells\n",
        "print(\"ðŸ  Environment ready â€“ go ahead and run the Activity-2 evaluation cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ…  Token works â€“ ready to create datasets & runs\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ LangSmith token prompt (works on any version of the SDK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, getpass\n",
        "from langsmith import Client      # `Client` exists in every release\n",
        "\n",
        "def ensure_langsmith_token():\n",
        "    if os.getenv(\"LANGSMITH_API_KEY\") or os.getenv(\"LANGCHAIN_API_KEY\"):\n",
        "        print(\"ðŸ”‘  Token already present in env â€“ good to go!\")\n",
        "        return\n",
        "\n",
        "    token = getpass.getpass(\"Paste your LangSmith API key: \").strip()\n",
        "    if not token:\n",
        "        raise RuntimeError(\"No token entered â€“ aborting evaluation.\")\n",
        "\n",
        "    # Set *both* names so whichever the SDK expects will resolve\n",
        "    os.environ[\"LANGSMITH_API_KEY\"] = token\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = token\n",
        "\n",
        "    # quick sanity-check\n",
        "    try:\n",
        "        Client().list_datasets(limit=1)      # cheap GET /datasets\n",
        "        print(\"âœ…  Token works â€“ ready to create datasets & runs\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Token validation failed: {e}\")\n",
        "\n",
        "ensure_langsmith_token()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created dataset jw_synth_qa_20250518T235914Z_bfb89 with 0 examples\n",
            "ðŸš€ Launching naive under project 'eval_naive_20250518T235914Z_73fdd' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_naive_20250518T235914Z_73fdd' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=8e4b9196-b276-4fe4-bc7e-1e390699edb8\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching bm25 under project 'eval_bm25_20250518T235914Z_159f8' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_bm25_20250518T235914Z_159f8' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=6385b4e3-1d86-4234-931a-95ad5f345c1a\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching contextual_compression under project 'eval_contextual_compression_20250518T235914Z_194e7' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_contextual_compression_20250518T235914Z_194e7' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=fe40d825-6777-4e4a-a093-ee8e5f47d533\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching multi_query under project 'eval_multi_query_20250518T235914Z_2df2b' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_multi_query_20250518T235914Z_2df2b' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=18ef6eeb-9b9a-4b15-9650-ac2b8a1151d5\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching parent_document under project 'eval_parent_document_20250518T235914Z_ff2e0' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_parent_document_20250518T235914Z_ff2e0' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=f6db63cf-7b51-4f5d-9b2f-fd446a0dbdf3\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching ensemble under project 'eval_ensemble_20250518T235914Z_504d2' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_ensemble_20250518T235914Z_504d2' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=38ab2278-d46c-4754-8219-40fabf18905d\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸš€ Launching semantic_chunking under project 'eval_semantic_chunking_20250518T235914Z_529c0' â€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aqsa/AI Projects/AIE6 Class Projects/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for project 'eval_semantic_chunking_20250518T235914Z_529c0' at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8/compare?selectedSessions=fadd788d-f9fe-40f5-9314-16fc7ef6ebbb\n",
            "\n",
            "View all tests for Dataset jw_synth_qa_20250518T235914Z_bfb89 at:\n",
            "https://smith.langchain.com/o/4e223e9d-b789-4c00-8d16-32ad70974f10/datasets/793567b0-434d-48a2-8bf8-4e90d87b34b8\n",
            "[------------------------------------------------->] 12/12ðŸŽ‰  All jobs submitted; check the LangSmith UI for each project.\n",
            "\n",
            "=== Latency Â· Tokens Â· Cost Summary ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>P50 s</th>\n",
              "      <th>P95 s</th>\n",
              "      <th>tokens</th>\n",
              "      <th>cost$</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>12.0</td>\n",
              "      <td>4.810</td>\n",
              "      <td>9.486</td>\n",
              "      <td>46839.0</td>\n",
              "      <td>1.4052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>12.0</td>\n",
              "      <td>4.124</td>\n",
              "      <td>5.580</td>\n",
              "      <td>19040.0</td>\n",
              "      <td>0.5712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>12.0</td>\n",
              "      <td>4.752</td>\n",
              "      <td>9.340</td>\n",
              "      <td>17397.0</td>\n",
              "      <td>0.5219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>12.0</td>\n",
              "      <td>7.450</td>\n",
              "      <td>10.200</td>\n",
              "      <td>39076.0</td>\n",
              "      <td>1.1723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>12.0</td>\n",
              "      <td>4.173</td>\n",
              "      <td>7.301</td>\n",
              "      <td>13348.0</td>\n",
              "      <td>0.4004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>12.0</td>\n",
              "      <td>9.850</td>\n",
              "      <td>12.303</td>\n",
              "      <td>74557.0</td>\n",
              "      <td>2.2367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic_chunking</th>\n",
              "      <td>12.0</td>\n",
              "      <td>5.044</td>\n",
              "      <td>10.127</td>\n",
              "      <td>37835.0</td>\n",
              "      <td>1.1350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        count  P50 s   P95 s   tokens   cost$\n",
              "naive                    12.0  4.810   9.486  46839.0  1.4052\n",
              "bm25                     12.0  4.124   5.580  19040.0  0.5712\n",
              "contextual_compression   12.0  4.752   9.340  17397.0  0.5219\n",
              "multi_query              12.0  7.450  10.200  39076.0  1.1723\n",
              "parent_document          12.0  4.173   7.301  13348.0  0.4004\n",
              "ensemble                 12.0  9.850  12.303  74557.0  2.2367\n",
              "semantic_chunking        12.0  5.044  10.127  37835.0  1.1350"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -------------------- ACTIVITY #2 Â· Simplified Evaluation --------------------\n",
        "#ACTIVITY #2 : LangSmith Evaluation  -----------------------\n",
        "# Prereqs (make sure you ran all cells above):\n",
        "#   â€¢ OPENAI_API_KEY  â€“ already set earlier\n",
        "#   â€¢ LANGCHAIN_API_KEY and LANGCHAIN_ENDPOINT (or LANGSMITH_API_KEY) â€“ for LangSmith\n",
        "#   â€¢ variable `dataset`  -> a ragas.Testset object created in Activity #1\n",
        "#   â€¢ retrieval chains: naive_retrieval_chain, bm25_retrieval_chain, \n",
        "#                       contextual_compression_retrieval_chain, multi_query_retrieval_chain,\n",
        "#                       parent_document_retrieval_chain, ensemble_retrieval_chain,\n",
        "#                       semantic_retrieval_chain##\n",
        "import os, time, uuid\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "from langsmith       import Client\n",
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 1. Build a unique dataset name and upload your examples  ---------------\n",
        "client       = Client()  # uses LANGSMITH_API_KEY\n",
        "ts           = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "DATASET_NAME = f\"jw_synth_qa_{ts}_{uuid.uuid4().hex[:5]}\"\n",
        "\n",
        "# Normalize the ragas test-set into 'question' and 'answer'\n",
        "try:\n",
        "    df = dataset.to_pandas()\n",
        "except AttributeError:\n",
        "    df = pd.DataFrame(dataset)\n",
        "\n",
        "RENAMES = {\n",
        "    \"query\":\"question\",\"user_input\":\"question\",\"inputs\":\"question\",\n",
        "    \"ground_truth\":\"answer\",\"reference\":\"answer\",\"outputs\":\"answer\"\n",
        "}\n",
        "df = df.rename(columns={old:new for old,new in RENAMES.items() if old in df})\n",
        "\n",
        "# Explode dict-columns if necessary\n",
        "if \"question\" not in df and \"inputs\" in df:\n",
        "    df[\"question\"] = df[\"inputs\"].apply(lambda d: d.get(\"query\") or d.get(\"user_input\"))\n",
        "if \"answer\"   not in df and \"outputs\" in df:\n",
        "    df[\"answer\"]   = df[\"outputs\"].apply(lambda d: d.get(\"answer\") or d.get(\"reference\"))\n",
        "\n",
        "if not {\"question\",\"answer\"} <= set(df):\n",
        "    raise ValueError(f\"Missing columns: {set(['question','answer'])-set(df)}\")\n",
        "\n",
        "# Create & populate the golden dataset\n",
        "golden = client.create_dataset(DATASET_NAME, description=\"Synthetic QA from RAGAS\")\n",
        "for _, row in df.iterrows():\n",
        "    client.create_example(\n",
        "        inputs     = {\"question\": row[\"question\"]},\n",
        "        outputs    = {\"answer\":   row[\"answer\"]},\n",
        "        dataset_id = golden.id,\n",
        "    )\n",
        "print(f\"âœ… Created dataset {DATASET_NAME} with {golden.example_count} examples\")\n",
        "\n",
        "# 2. Prepare evaluators & LLM ---------------------------------------------\n",
        "eval_llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
        "\n",
        "eval_cfg = RunEvalConfig(\n",
        "    eval_llm=eval_llm,\n",
        "    evaluators=[\n",
        "        RunEvalConfig.QA(),    # built-in correctness\n",
        "        RunEvalConfig.LabeledCriteria({\n",
        "            \"rotten_tomatoes\": (\n",
        "                \"Rate from 1â€“5 how satisfyingly this answer would \"\n",
        "                \"land on a Rotten-Tomatoesâ€“style review for helpfulness.\"\n",
        "            )\n",
        "        }),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# 3. Launch one run per retriever under its own unique project -------------\n",
        "chains = {\n",
        "    \"naive\"                 : naive_retrieval_chain,\n",
        "    \"bm25\"                  : bm25_retrieval_chain,\n",
        "    \"contextual_compression\": contextual_compression_retrieval_chain,\n",
        "    \"multi_query\"           : multi_query_retrieval_chain,\n",
        "    \"parent_document\"       : parent_document_retrieval_chain,\n",
        "    \"ensemble\"              : ensemble_retrieval_chain,\n",
        "    \"semantic_chunking\"     : semantic_retrieval_chain,\n",
        "}\n",
        "\n",
        "run_handles = {}\n",
        "project_map = {}\n",
        "\n",
        "for name, chain in chains.items():\n",
        "    proj = f\"eval_{name}_{ts}_{uuid.uuid4().hex[:5]}\"\n",
        "    project_map[name] = proj\n",
        "    print(f\"ðŸš€ Launching {name} under project '{proj}' â€¦\")\n",
        "    run_handles[name] = run_on_dataset(\n",
        "        client               = client,\n",
        "        dataset_name         = DATASET_NAME,\n",
        "        llm_or_chain_factory = lambda c=chain: c,\n",
        "        evaluation           = eval_cfg,\n",
        "        project_name         = proj,\n",
        "        tags                 = [\"activity-2\", name],\n",
        "    )\n",
        "\n",
        "print(\"ðŸŽ‰  All jobs submitted; check the LangSmith UI for each project.\")\n",
        "\n",
        "# 4. Optional: Summary of latency & cost ----------------------------------\n",
        "# â”€â”€ 4b. Latency Â· Tokens Â· Cost summary using the exact project_map â”€â”€â”€â”€â”€â”€\n",
        "PRICE_PER_1K = 0.03  # USD per 1K tokens\n",
        "time.sleep(5)  # give runs a moment to register\n",
        "\n",
        "def stats_for_project(proj_name: str):\n",
        "    try:\n",
        "        runs = list(client.list_runs(\n",
        "            project_name=proj_name,\n",
        "            execution_order=1,\n",
        "            filter_state=\"completed\"\n",
        "        ))\n",
        "    except Exception:\n",
        "        return {\"count\": 0, \"P50 s\": None, \"P95 s\": None, \"tokens\": 0, \"cost$\": 0}\n",
        "    # Compute latencies from the run objects\n",
        "    latencies = []\n",
        "    for r in runs:\n",
        "        if r.start_time and r.end_time:\n",
        "            # r.start_time and r.end_time are datetimes\n",
        "            delta = r.end_time - r.start_time\n",
        "            latencies.append(delta.total_seconds())\n",
        "    lat = np.array(latencies, float)\n",
        "\n",
        "    # Tokens is still r.total_tokens\n",
        "    tok = np.array([r.total_tokens or 0 for r in runs], int)\n",
        "    return {\n",
        "        \"count\"   : len(runs),\n",
        "        \"P50 s\"   : np.percentile(lat, 50).round(3) if len(runs) else None,\n",
        "        \"P95 s\"   : np.percentile(lat, 95).round(3) if len(runs) else None,\n",
        "        \"tokens\"  : tok.sum(),\n",
        "        \"cost$\"   : (tok.sum()/1000 * PRICE_PER_1K).round(4),\n",
        "    }\n",
        "\n",
        "# Build summary by iterating over the exact project_map\n",
        "summary = pd.DataFrame({\n",
        "    name: stats_for_project(proj_name)\n",
        "    for name, proj_name in project_map.items()\n",
        "}).T\n",
        "\n",
        "print(\"\\n=== Latency Â· Tokens Â· Cost Summary ===\")\n",
        "display(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary Paragraph:\n",
        "1) The Ensemble modeling was most expensive, while Parent_document is cheapest. This is proportional to the amount of tokens utilized.\n",
        "2) In terms of latency, P95 is best for BM25 while worst for Ensemble; while P50 also follows the same patterns. This suggest BM25 can be fastest, while keeping costs reasonable\n",
        "\n",
        "Worth noticing, Ensemble is most expensive and has highest latency\n",
        "\n",
        "In terms of performance, our metrics for Correctness and Rotten Tomatoes can be seen in LangSmith UI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
